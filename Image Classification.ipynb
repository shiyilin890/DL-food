{"cells":[{"cell_type":"code","source":["from __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\nplt.ion()  \n\nuse_gpu = torch.cuda.is_available()\nif use_gpu:\n    print(\"Using CUDA\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28783a30-590d-4159-b052-95ec872b29b8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Using CUDA\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Using CUDA\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["data_dir = '/dbfs/mnt/images/FoodRecipe'\nTRAIN = 'images'\nTEST = 'testing'\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"962ee7e4-156e-4354-b20e-7afaa6c2614c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[49]: device(type=&#39;cuda&#39;, index=0)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[49]: device(type=&#39;cuda&#39;, index=0)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["transform_train = transforms.Compose([transforms.Resize(256),\n        transforms.RandomCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \ntransform_val = transforms.Compose([transforms.Resize(256),\n        transforms.RandomCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"572cb21e-0cd5-410e-9630-317bbf1466ab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["Train = datasets.ImageFolder(os.path.join(data_dir, TRAIN), transform = transform_train)\nTest = datasets.ImageFolder(os.path.join(data_dir, TEST), transform = transform_val)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fdc68792-e995-410a-9d0d-1a954a8e58a9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"Loaded {} images under {}\".format(\"Train\", len(Train.imgs)))\nprint(\"Loaded {} images under {}\".format(\"Train\", len(Test.imgs)))\nprint(\"{} number of classes\".format(len(Train.classes)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"333646b9-42cd-47c2-bf01-21f40d4ad147"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Loaded Train images under 75750\nLoaded Train images under 25250\n101 number of classes\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Loaded Train images under 75750\nLoaded Train images under 25250\n101 number of classes\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["Train_Loader = torch.utils.data.DataLoader(Train, batch_size = 64, shuffle = True, num_workers = 4)\nTest_Loader = torch.utils.data.DataLoader(Test, batch_size = 64, shuffle = False, num_workers = 4)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"658c4531-c783-4fb1-ba6e-5c4b8c6c1164"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(Train_Loader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66c1bd09-7c63-4012-8017-8a499b7f0a64"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["vgg16 = models.vgg16(pretrained = True)\nfor param in vgg16.features.parameters():\n    param.require_grad = True\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"083bbaf9-5bac-466e-9a44-19bb67b75602"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["num_features = vgg16.classifier[6].in_features\nfeatures = list(vgg16.classifier.children())[:-1] # Remove last layer\nfeatures.extend(nn.Sequential(nn.Linear(num_features,4096),nn.ReLU(inplace=True),nn.Linear(4096,4096),nn.ReLU(inplace=True),\n               nn.Linear(num_features, 101)).to(device)) \nvgg16.classifier = nn.Sequential(*features) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ead8913c-633e-4c83-a43f-0c3a6594703b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["vgg16"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46ec7ed4-b419-4c07-80bb-3c3b6b583bd7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[57]: VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=4096, bias=True)\n    (7): ReLU(inplace=True)\n    (8): Linear(in_features=4096, out_features=4096, bias=True)\n    (9): ReLU(inplace=True)\n    (10): Linear(in_features=4096, out_features=101, bias=True)\n  )\n)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[57]: VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=4096, bias=True)\n    (7): ReLU(inplace=True)\n    (8): Linear(in_features=4096, out_features=4096, bias=True)\n    (9): ReLU(inplace=True)\n    (10): Linear(in_features=4096, out_features=101, bias=True)\n  )\n)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef accuracy(output, target):\n    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n    batch_size = target.shape[0]\n\n    _, pred = torch.max(output, dim=-1)\n\n    correct = pred.eq(target).sum() * 1.0\n\n    acc = correct / batch_size\n\n    return acc\n\ndef train(epoch, data_loader, model, optimizer, criterion):\n\n    iter_time = AverageMeter()\n    losses = AverageMeter()\n    acc = AverageMeter()\n    model.train()\n    for idx, (data, target) in enumerate(data_loader):\n        start = time.time()\n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n\n        #############################################################################\n        # TODO: Complete the body of training loop                                  #\n        #       1. forward data batch to the model                                  #\n        #       2. Compute batch loss                                               #\n        #       3. Compute gradients and update model parameters                    #\n        #############################################################################\n    \n        out = model.forward(data)\n        loss = criterion(out, target)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        #############################################################################\n        #                              END OF YOUR CODE                             #\n        #############################################################################\n\n        batch_acc = accuracy(out, target)\n\n        losses.update(loss, out.shape[0])\n        acc.update(batch_acc, out.shape[0])\n\n        iter_time.update(time.time() - start)\n        if idx % 10 == 0:\n            print(('Epoch: [{0}][{1}/{2}]\\t'\n                   'Time {iter_time.val:.3f} ({iter_time.avg:.3f})\\t'\n                   'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n                   'Prec @1 {top1.val:.4f} ({top1.avg:.4f})\\t')\n                   .format(epoch, idx, len(data_loader), iter_time=iter_time, loss=losses, top1=acc))\n    return acc.avg, losses.avg\n\n\ndef validate(epoch, val_loader, model, criterion):\n    iter_time = AverageMeter()\n    losses = AverageMeter()\n    acc = AverageMeter()\n\n    num_class = 101\n    cm =torch.zeros(num_class, num_class)\n    # evaluation loop\n    for idx, (data, target) in enumerate(val_loader):\n        start = time.time()\n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        #############################################################################\n        # TODO: Complete the body of training loop                                  #\n        #       HINT: torch.no_grad()                                               #\n        #############################################################################\n        with torch.no_grad():\n            out = model(data)\n            loss = criterion(out, target)\n        #############################################################################\n        #                              END OF YOUR CODE                             #\n        #############################################################################\n\n        batch_acc = accuracy(out, target)\n\n        # update confusion matrix\n        _, preds = torch.max(out, 1)\n        for t, p in zip(target.view(-1), preds.view(-1)):\n            cm[t.long(), p.long()] += 1\n\n        losses.update(loss, out.shape[0])\n        acc.update(batch_acc, out.shape[0])\n\n        iter_time.update(time.time() - start)\n        if idx % 10 == 0:\n            print(('Epoch: [{0}][{1}/{2}]\\t'\n               'Time {iter_time.val:.3f} ({iter_time.avg:.3f})\\t')\n               .format(epoch, idx, len(val_loader), iter_time=iter_time, loss=losses, top1=acc))\n    cm = cm / cm.sum(1)\n    per_cls_acc = cm.diag().detach().numpy().tolist()\n    for i, acc_i in enumerate(per_cls_acc):\n        print(\"Accuracy of Class {}: {:.4f}\".format(i, acc_i))\n\n    print(\"* Prec @1: {top1.avg:.4f}\".format(top1=acc))\n    return acc.avg, losses.avg, cm\n  \ndef main(train_loader, test_loader, model, criterion, optimizer, epochs, scheduler):\n    \n    if torch.cuda.is_available():\n        model = model.cuda()\n\n    best = 0.0\n    best_cm = None\n    best_model = None\n    train_acc = []\n    train_loss = []\n    val_acc = []\n    val_loss = []\n    for epoch in range(epochs):\n        # train loop\n        train_ac, train_ls = train(epoch, train_loader, model, optimizer, criterion)\n\n        # validation loop\n        validation_acc, validation_loss, cm = validate(epoch, test_loader, model, criterion)\n\n        if validation_acc > best:\n            best = validation_acc\n            best_cm = cm\n        train_acc.append(train_ac)\n        train_loss.append(train_ls)\n        val_acc.append(validation_acc)\n        val_loss.append(validation_loss)\n        scheduler.step()\n    print('Best Prec @1 Acccuracy: {:.4f}'.format(best))\n    per_cls_acc = best_cm.diag().detach().numpy().tolist()\n    for i, acc_i in enumerate(per_cls_acc):\n        print(\"Accuracy of Class {}: {:.4f}\".format(i, acc_i))\n    return train_acc, train_loss, val_acc, val_loss"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04e6262d-41d2-4d62-842e-aa89c4b34d46"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(vgg16.parameters(), momentum= 0.9, lr=0.02)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fdc875d4-c6a5-44c1-9998-c898ae325d58"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["train_acc, train_loss, val_acc, val_loss = main(Train_Loader, Test_Loader, vgg16, criterion, optimizer, 10, exp_lr_scheduler)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3feaf35-a6a5-4a54-aca3-0147dd3332c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Epoch: [0][0/1184]\tTime 0.035 (0.035)\tLoss 4.6255 (4.6255)\tPrec @1 0.0312 (0.0312)\t\nEpoch: [0][10/1184]\tTime 0.855 (0.702)\tLoss 4.6506 (4.6169)\tPrec @1 0.0000 (0.0156)\t\nEpoch: [0][20/1184]\tTime 0.861 (0.737)\tLoss 4.5632 (4.6097)\tPrec @1 0.0156 (0.0149)\t\nEpoch: [0][30/1184]\tTime 0.867 (0.750)\tLoss 4.5064 (4.5805)\tPrec @1 0.0312 (0.0202)\t\nEpoch: [0][40/1184]\tTime 0.868 (0.758)\tLoss 4.4831 (4.5591)\tPrec @1 0.0625 (0.0267)\t\nEpoch: [0][50/1184]\tTime 0.874 (0.763)\tLoss 4.4054 (4.5419)\tPrec @1 0.0312 (0.0270)\t\nEpoch: [0][60/1184]\tTime 0.879 (0.768)\tLoss 4.2485 (4.5141)\tPrec @1 0.0625 (0.0295)\t\nEpoch: [0][70/1184]\tTime 0.884 (0.771)\tLoss 4.2441 (4.4631)\tPrec @1 0.0938 (0.0363)\t\nEpoch: [0][80/1184]\tTime 0.887 (0.775)\tLoss 3.9830 (4.4208)\tPrec @1 0.0469 (0.0411)\t\nEpoch: [0][90/1184]\tTime 0.891 (0.777)\tLoss 3.8274 (4.3870)\tPrec @1 0.1250 (0.0452)\t\nEpoch: [0][100/1184]\tTime 0.901 (0.783)\tLoss 4.0999 (4.3502)\tPrec @1 0.0625 (0.0476)\t\nEpoch: [0][110/1184]\tTime 0.888 (0.784)\tLoss 3.9097 (4.3165)\tPrec @1 0.0625 (0.0511)\t\nEpoch: [0][120/1184]\tTime 0.888 (0.786)\tLoss 4.0645 (4.2923)\tPrec @1 0.0625 (0.0540)\t\nEpoch: [0][130/1184]\tTime 0.901 (0.788)\tLoss 4.1812 (4.2641)\tPrec @1 0.0312 (0.0568)\t\nEpoch: [0][140/1184]\tTime 0.905 (0.789)\tLoss 3.4618 (4.2329)\tPrec @1 0.1719 (0.0609)\t\nEpoch: [0][150/1184]\tTime 0.901 (0.791)\tLoss 3.7848 (4.2008)\tPrec @1 0.1094 (0.0662)\t\nEpoch: [0][160/1184]\tTime 0.907 (0.792)\tLoss 3.9122 (4.1703)\tPrec @1 0.0781 (0.0689)\t\nEpoch: [0][170/1184]\tTime 0.910 (0.794)\tLoss 3.5266 (4.1367)\tPrec @1 0.1719 (0.0736)\t\nEpoch: [0][180/1184]\tTime 0.909 (0.795)\tLoss 3.9242 (4.1080)\tPrec @1 0.0625 (0.0780)\t\nEpoch: [0][190/1184]\tTime 0.906 (0.796)\tLoss 3.7460 (4.0838)\tPrec @1 0.1719 (0.0813)\t\nEpoch: [0][200/1184]\tTime 0.906 (0.797)\tLoss 3.5774 (4.0570)\tPrec @1 0.1094 (0.0855)\t\nEpoch: [0][210/1184]\tTime 0.906 (0.798)\tLoss 2.9064 (4.0320)\tPrec @1 0.3438 (0.0889)\t\nEpoch: [0][220/1184]\tTime 0.907 (0.799)\tLoss 3.6764 (4.0166)\tPrec @1 0.0312 (0.0914)\t\nEpoch: [0][230/1184]\tTime 0.910 (0.800)\tLoss 3.9623 (3.9995)\tPrec @1 0.1094 (0.0947)\t\nEpoch: [0][240/1184]\tTime 0.911 (0.801)\tLoss 3.7852 (3.9888)\tPrec @1 0.1562 (0.0969)\t\nEpoch: [0][250/1184]\tTime 0.911 (0.802)\tLoss 3.2099 (3.9666)\tPrec @1 0.2031 (0.1005)\t\nEpoch: [0][260/1184]\tTime 0.908 (0.802)\tLoss 3.4049 (3.9494)\tPrec @1 0.1406 (0.1028)\t\nEpoch: [0][270/1184]\tTime 0.905 (0.803)\tLoss 3.1229 (3.9286)\tPrec @1 0.2500 (0.1064)\t\nEpoch: [0][280/1184]\tTime 0.906 (0.803)\tLoss 3.5374 (3.9086)\tPrec @1 0.1250 (0.1090)\t\nEpoch: [0][290/1184]\tTime 0.919 (0.804)\tLoss 3.6359 (3.8962)\tPrec @1 0.1719 (0.1122)\t\nEpoch: [0][300/1184]\tTime 0.913 (0.805)\tLoss 3.7685 (3.8838)\tPrec @1 0.1094 (0.1140)\t\nEpoch: [0][310/1184]\tTime 0.911 (0.805)\tLoss 3.5900 (3.8724)\tPrec @1 0.1250 (0.1156)\t\nEpoch: [0][320/1184]\tTime 0.911 (0.806)\tLoss 2.9778 (3.8543)\tPrec @1 0.2344 (0.1183)\t\nEpoch: [0][330/1184]\tTime 0.921 (0.806)\tLoss 3.6571 (3.8420)\tPrec @1 0.1250 (0.1205)\t\nEpoch: [0][340/1184]\tTime 0.908 (0.807)\tLoss 3.4196 (3.8282)\tPrec @1 0.1875 (0.1226)\t\nEpoch: [0][350/1184]\tTime 0.909 (0.807)\tLoss 3.0921 (3.8126)\tPrec @1 0.2500 (0.1249)\t\nEpoch: [0][360/1184]\tTime 0.919 (0.807)\tLoss 2.8594 (3.7953)\tPrec @1 0.2656 (0.1280)\t\nEpoch: [0][370/1184]\tTime 0.908 (0.808)\tLoss 3.5253 (3.7814)\tPrec @1 0.1875 (0.1301)\t\nEpoch: [0][380/1184]\tTime 0.910 (0.808)\tLoss 3.1436 (3.7658)\tPrec @1 0.2969 (0.1331)\t\nEpoch: [0][390/1184]\tTime 0.911 (0.809)\tLoss 3.2317 (3.7502)\tPrec @1 0.1875 (0.1362)\t\nEpoch: [0][400/1184]\tTime 0.909 (0.809)\tLoss 3.6256 (3.7383)\tPrec @1 0.1094 (0.1382)\t\nEpoch: [0][410/1184]\tTime 0.911 (0.809)\tLoss 2.9443 (3.7258)\tPrec @1 0.2969 (0.1406)\t\nEpoch: [0][420/1184]\tTime 0.914 (0.810)\tLoss 3.0577 (3.7144)\tPrec @1 0.2812 (0.1428)\t\nEpoch: [0][430/1184]\tTime 0.912 (0.810)\tLoss 2.7955 (3.7014)\tPrec @1 0.2969 (0.1448)\t\nEpoch: [0][440/1184]\tTime 0.914 (0.810)\tLoss 3.2757 (3.6885)\tPrec @1 0.2656 (0.1472)\t\nEpoch: [0][450/1184]\tTime 0.911 (0.811)\tLoss 2.7152 (3.6733)\tPrec @1 0.2656 (0.1500)\t\nEpoch: [0][460/1184]\tTime 0.909 (0.811)\tLoss 2.8739 (3.6632)\tPrec @1 0.3281 (0.1517)\t\nEpoch: [0][470/1184]\tTime 0.912 (0.811)\tLoss 2.6857 (3.6509)\tPrec @1 0.2969 (0.1539)\t\nEpoch: [0][480/1184]\tTime 0.908 (0.811)\tLoss 2.7424 (3.6383)\tPrec @1 0.3750 (0.1559)\t\nEpoch: [0][490/1184]\tTime 0.910 (0.812)\tLoss 2.8291 (3.6253)\tPrec @1 0.2344 (0.1578)\t\nEpoch: [0][500/1184]\tTime 0.914 (0.812)\tLoss 3.2637 (3.6164)\tPrec @1 0.1875 (0.1593)\t\nEpoch: [0][510/1184]\tTime 0.908 (0.812)\tLoss 2.7588 (3.6044)\tPrec @1 0.2656 (0.1612)\t\nEpoch: [0][520/1184]\tTime 0.911 (0.812)\tLoss 2.6348 (3.5916)\tPrec @1 0.3125 (0.1633)\t\nEpoch: [0][530/1184]\tTime 0.910 (0.812)\tLoss 3.2222 (3.5802)\tPrec @1 0.2344 (0.1650)\t\nEpoch: [0][540/1184]\tTime 0.908 (0.812)\tLoss 2.7243 (3.5699)\tPrec @1 0.2812 (0.1666)\t\nEpoch: [0][550/1184]\tTime 0.919 (0.813)\tLoss 2.6078 (3.5585)\tPrec @1 0.3281 (0.1688)\t\nEpoch: [0][560/1184]\tTime 0.916 (0.813)\tLoss 2.6823 (3.5452)\tPrec @1 0.4062 (0.1712)\t\nEpoch: [0][570/1184]\tTime 0.919 (0.813)\tLoss 3.2582 (3.5402)\tPrec @1 0.1875 (0.1721)\t\nEpoch: [0][580/1184]\tTime 0.921 (0.813)\tLoss 3.0288 (3.5319)\tPrec @1 0.2188 (0.1738)\t\nEpoch: [0][590/1184]\tTime 0.921 (0.813)\tLoss 3.2648 (3.5237)\tPrec @1 0.2031 (0.1750)\t\nEpoch: [0][600/1184]\tTime 0.911 (0.813)\tLoss 2.8146 (3.5117)\tPrec @1 0.2812 (0.1772)\t\nEpoch: [0][610/1184]\tTime 0.909 (0.814)\tLoss 3.1244 (3.5015)\tPrec @1 0.2969 (0.1792)\t\nEpoch: [0][620/1184]\tTime 0.911 (0.814)\tLoss 3.5229 (3.4951)\tPrec @1 0.1875 (0.1804)\t\nEpoch: [0][630/1184]\tTime 0.910 (0.814)\tLoss 3.3933 (3.4869)\tPrec @1 0.1875 (0.1818)\t\nEpoch: [0][640/1184]\tTime 0.912 (0.814)\tLoss 2.9906 (3.4784)\tPrec @1 0.2188 (0.1831)\t\nEpoch: [0][650/1184]\tTime 0.921 (0.814)\tLoss 2.8607 (3.4708)\tPrec @1 0.2969 (0.1844)\t\nEpoch: [0][660/1184]\tTime 0.909 (0.814)\tLoss 2.9139 (3.4619)\tPrec @1 0.2812 (0.1862)\t\nEpoch: [0][670/1184]\tTime 0.913 (0.814)\tLoss 2.6917 (3.4543)\tPrec @1 0.2812 (0.1875)\t\nEpoch: [0][680/1184]\tTime 0.909 (0.815)\tLoss 2.5046 (3.4445)\tPrec @1 0.4062 (0.1893)\t\nEpoch: [0][690/1184]\tTime 0.909 (0.815)\tLoss 2.4694 (3.4348)\tPrec @1 0.3594 (0.1915)\t\nEpoch: [0][700/1184]\tTime 0.923 (0.815)\tLoss 3.1343 (3.4283)\tPrec @1 0.2500 (0.1925)\t\nEpoch: [0][710/1184]\tTime 0.923 (0.815)\tLoss 3.1320 (3.4200)\tPrec @1 0.3281 (0.1939)\t\nEpoch: [0][720/1184]\tTime 0.908 (0.815)\tLoss 2.4213 (3.4105)\tPrec @1 0.3438 (0.1952)\t\nEpoch: [0][730/1184]\tTime 0.913 (0.815)\tLoss 2.8053 (3.4036)\tPrec @1 0.2812 (0.1962)\t\nEpoch: [0][740/1184]\tTime 0.909 (0.815)\tLoss 2.9226 (3.3966)\tPrec @1 0.2969 (0.1972)\t\nEpoch: [0][750/1184]\tTime 0.910 (0.815)\tLoss 2.6565 (3.3884)\tPrec @1 0.3281 (0.1985)\t\nEpoch: [0][760/1184]\tTime 0.909 (0.815)\tLoss 2.7720 (3.3809)\tPrec @1 0.2656 (0.1997)\t\nEpoch: [0][770/1184]\tTime 0.907 (0.815)\tLoss 2.3973 (3.3731)\tPrec @1 0.4062 (0.2011)\t\nEpoch: [0][780/1184]\tTime 0.906 (0.815)\tLoss 2.7160 (3.3654)\tPrec @1 0.2812 (0.2023)\t\nEpoch: [0][790/1184]\tTime 0.909 (0.816)\tLoss 3.2068 (3.3587)\tPrec @1 0.2188 (0.2034)\t\nEpoch: [0][800/1184]\tTime 0.909 (0.816)\tLoss 2.8783 (3.3507)\tPrec @1 0.2812 (0.2048)\t\nEpoch: [0][810/1184]\tTime 0.908 (0.816)\tLoss 2.8588 (3.3436)\tPrec @1 0.2500 (0.2059)\t\nEpoch: [0][820/1184]\tTime 0.910 (0.816)\tLoss 2.7791 (3.3354)\tPrec @1 0.2969 (0.2077)\t\nEpoch: [0][830/1184]\tTime 0.908 (0.816)\tLoss 2.7995 (3.3296)\tPrec @1 0.2969 (0.2087)\t\nEpoch: [0][840/1184]\tTime 0.912 (0.816)\tLoss 2.6748 (3.3234)\tPrec @1 0.3750 (0.2098)\t\nEpoch: [0][850/1184]\tTime 0.908 (0.816)\tLoss 2.6020 (3.3174)\tPrec @1 0.3438 (0.2111)\t\nEpoch: [0][860/1184]\tTime 0.907 (0.816)\tLoss 2.8461 (3.3121)\tPrec @1 0.2969 (0.2120)\t\nEpoch: [0][870/1184]\tTime 0.913 (0.816)\tLoss 3.7709 (3.3071)\tPrec @1 0.1719 (0.2131)\t\nEpoch: [0][880/1184]\tTime 0.923 (0.816)\tLoss 3.0221 (3.3019)\tPrec @1 0.2500 (0.2142)\t\nEpoch: [0][890/1184]\tTime 0.919 (0.816)\tLoss 2.7369 (3.2970)\tPrec @1 0.3594 (0.2149)\t\nEpoch: [0][900/1184]\tTime 0.921 (0.816)\tLoss 2.5622 (3.2908)\tPrec @1 0.3594 (0.2162)\t\nEpoch: [0][910/1184]\tTime 0.909 (0.816)\tLoss 2.8604 (3.2843)\tPrec @1 0.2500 (0.2172)\t\nEpoch: [0][920/1184]\tTime 0.915 (0.816)\tLoss 2.9386 (3.2765)\tPrec @1 0.3281 (0.2186)\t\nEpoch: [0][930/1184]\tTime 0.921 (0.816)\tLoss 2.5872 (3.2698)\tPrec @1 0.3438 (0.2202)\t\nEpoch: [0][940/1184]\tTime 0.910 (0.817)\tLoss 2.5199 (3.2632)\tPrec @1 0.3281 (0.2214)\t\nEpoch: [0][950/1184]\tTime 0.915 (0.817)\tLoss 3.0609 (3.2578)\tPrec @1 0.2500 (0.2225)\t\nEpoch: [0][960/1184]\tTime 0.910 (0.817)\tLoss 3.0064 (3.2530)\tPrec @1 0.2500 (0.2234)\t\nEpoch: [0][970/1184]\tTime 0.909 (0.817)\tLoss 2.7867 (3.2492)\tPrec @1 0.2812 (0.2241)\t\nEpoch: [0][980/1184]\tTime 0.909 (0.817)\tLoss 2.5705 (3.2434)\tPrec @1 0.4219 (0.2252)\t\nEpoch: [0][990/1184]\tTime 0.907 (0.817)\tLoss 3.5240 (3.2394)\tPrec @1 0.1250 (0.2256)\t\nEpoch: [0][1000/1184]\tTime 0.911 (0.817)\tLoss 3.0254 (3.2345)\tPrec @1 0.2500 (0.2267)\t\nEpoch: [0][1010/1184]\tTime 0.908 (0.817)\tLoss 2.8754 (3.2315)\tPrec @1 0.3750 (0.2275)\t\nEpoch: [0][1020/1184]\tTime 0.908 (0.817)\tLoss 2.4845 (3.2265)\tPrec @1 0.4219 (0.2286)\t\nEpoch: [0][1030/1184]\tTime 0.910 (0.817)\tLoss 2.3622 (3.2208)\tPrec @1 0.3594 (0.2298)\t\nEpoch: [0][1040/1184]\tTime 0.908 (0.817)\tLoss 2.6029 (3.2143)\tPrec @1 0.3125 (0.2310)\t\nEpoch: [0][1050/1184]\tTime 0.908 (0.817)\tLoss 2.7962 (3.2092)\tPrec @1 0.2812 (0.2316)\t\nEpoch: [0][1060/1184]\tTime 0.910 (0.817)\tLoss 3.1267 (3.2040)\tPrec @1 0.2812 (0.2329)\t\nEpoch: [0][1070/1184]\tTime 0.911 (0.817)\tLoss 2.9330 (3.1983)\tPrec @1 0.2812 (0.2338)\t\nEpoch: [0][1080/1184]\tTime 0.914 (0.817)\tLoss 3.3649 (3.1943)\tPrec @1 0.1719 (0.2347)\t\nEpoch: [0][1090/1184]\tTime 0.907 (0.817)\tLoss 1.9671 (3.1889)\tPrec @1 0.4844 (0.2357)\t\nEpoch: [0][1100/1184]\tTime 0.908 (0.817)\tLoss 2.4981 (3.1841)\tPrec @1 0.3438 (0.2364)\t\nEpoch: [0][1110/1184]\tTime 0.908 (0.817)\tLoss 2.6305 (3.1791)\tPrec @1 0.3125 (0.2373)\t\nEpoch: [0][1120/1184]\tTime 0.910 (0.817)\tLoss 2.4979 (3.1740)\tPrec @1 0.3750 (0.2383)\t\nEpoch: [0][1130/1184]\tTime 0.910 (0.817)\tLoss 2.4649 (3.1681)\tPrec @1 0.3750 (0.2393)\t\nEpoch: [0][1140/1184]\tTime 0.911 (0.817)\tLoss 2.0926 (3.1619)\tPrec @1 0.4688 (0.2405)\t\nEpoch: [0][1150/1184]\tTime 0.909 (0.817)\tLoss 2.6112 (3.1563)\tPrec @1 0.3438 (0.2416)\t\nEpoch: [0][1160/1184]\tTime 0.907 (0.817)\tLoss 2.6732 (3.1521)\tPrec @1 0.2812 (0.2424)\t\nEpoch: [0][1170/1184]\tTime 0.910 (0.817)\tLoss 2.3972 (3.1462)\tPrec @1 0.3594 (0.2437)\t\nEpoch: [0][1180/1184]\tTime 0.908 (0.817)\tLoss 2.7266 (3.1415)\tPrec @1 0.2969 (0.2446)\t\nEpoch: [0][0/395]\tTime 0.282 (0.282)\t\nEpoch: [0][10/395]\tTime 0.286 (0.286)\t\nEpoch: [0][20/395]\tTime 0.282 (0.287)\t\nEpoch: [0][30/395]\tTime 0.292 (0.287)\t\nEpoch: [0][40/395]\tTime 0.285 (0.288)\t\nEpoch: [0][50/395]\tTime 0.286 (0.288)\t\nEpoch: [0][60/395]\tTime 0.281 (0.288)\t\nEpoch: [0][70/395]\tTime 0.302 (0.288)\t\nEpoch: [0][80/395]\tTime 0.286 (0.288)\t\nEpoch: [0][90/395]\tTime 0.291 (0.288)\t\nEpoch: [0][100/395]\tTime 0.293 (0.288)\t\nEpoch: [0][110/395]\tTime 0.290 (0.288)\t\nEpoch: [0][120/395]\tTime 0.294 (0.288)\t\nEpoch: [0][130/395]\tTime 0.286 (0.288)\t\nEpoch: [0][140/395]\tTime 0.298 (0.288)\t\nEpoch: [0][150/395]\tTime 0.289 (0.288)\t\nEpoch: [0][160/395]\tTime 0.293 (0.288)\t\nEpoch: [0][170/395]\tTime 0.286 (0.288)\t\nEpoch: [0][180/395]\tTime 0.291 (0.288)\t\nEpoch: [0][190/395]\tTime 0.286 (0.288)\t\nEpoch: [0][200/395]\tTime 0.284 (0.288)\t\nEpoch: [0][210/395]\tTime 0.284 (0.288)\t\nEpoch: [0][220/395]\tTime 0.281 (0.288)\t\nEpoch: [0][230/395]\tTime 0.285 (0.288)\t\nEpoch: [0][240/395]\tTime 0.290 (0.288)\t\nEpoch: [0][250/395]\tTime 0.285 (0.288)\t\nEpoch: [0][260/395]\tTime 0.284 (0.288)\t\nEpoch: [0][270/395]\tTime 0.293 (0.288)\t\nEpoch: [0][280/395]\tTime 0.286 (0.288)\t\nEpoch: [0][290/395]\tTime 0.290 (0.288)\t\nEpoch: [0][300/395]\tTime 0.297 (0.288)\t\nEpoch: [0][310/395]\tTime 0.283 (0.288)\t\nEpoch: [0][320/395]\tTime 0.284 (0.288)\t\nEpoch: [0][330/395]\tTime 0.282 (0.288)\t\nEpoch: [0][340/395]\tTime 0.297 (0.288)\t\nEpoch: [0][350/395]\tTime 0.289 (0.288)\t\nEpoch: [0][360/395]\tTime 0.292 (0.288)\t\nEpoch: [0][370/395]\tTime 0.284 (0.288)\t\nEpoch: [0][380/395]\tTime 0.292 (0.288)\t\nEpoch: [0][390/395]\tTime 0.290 (0.288)\t\nAccuracy of Class 0: 0.0720\nAccuracy of Class 1: 0.5560\nAccuracy of Class 2: 0.4520\nAccuracy of Class 3: 0.8200\nAccuracy of Class 4: 0.2560\nAccuracy of Class 5: 0.3520\nAccuracy of Class 6: 0.8080\nAccuracy of Class 7: 0.4480\nAccuracy of Class 8: 0.2920\nAccuracy of Class 9: 0.0000\nAccuracy of Class 10: 0.3360\nAccuracy of Class 11: 0.7160\nAccuracy of Class 12: 0.2480\nAccuracy of Class 13: 0.1040\nAccuracy of Class 14: 0.4080\nAccuracy of Class 15: 0.0840\nAccuracy of Class 16: 0.2840\nAccuracy of Class 17: 0.3480\nAccuracy of Class 18: 0.0920\nAccuracy of Class 19: 0.4720\nAccuracy of Class 20: 0.6200\nAccuracy of Class 21: 0.3800\nAccuracy of Class 22: 0.2240\nAccuracy of Class 23: 0.4880\nAccuracy of Class 24: 0.8600\nAccuracy of Class 25: 0.2360\nAccuracy of Class 26: 0.5160\nAccuracy of Class 27: 0.3160\nAccuracy of Class 28: 0.3320\nAccuracy of Class 29: 0.3320\nAccuracy of Class 30: 0.4240\nAccuracy of Class 31: 0.5400\nAccuracy of Class 32: 0.7160\nAccuracy of Class 33: 0.9560\nAccuracy of Class 34: 0.5440\nAccuracy of Class 35: 0.5000\nAccuracy of Class 36: 0.2480\nAccuracy of Class 37: 0.1840\nAccuracy of Class 38: 0.3720\nAccuracy of Class 39: 0.2680\nAccuracy of Class 40: 0.5680\nAccuracy of Class 41: 0.2400\nAccuracy of Class 42: 0.1320\nAccuracy of Class 43: 0.3720\nAccuracy of Class 44: 0.7080\nAccuracy of Class 45: 0.6280\nAccuracy of Class 46: 0.5120\nAccuracy of Class 47: 0.1400\nAccuracy of Class 48: 0.2440\nAccuracy of Class 49: 0.0880\nAccuracy of Class 50: 0.5080\nAccuracy of Class 51: 0.7360\nAccuracy of Class 52: 0.0400\nAccuracy of Class 53: 0.2320\nAccuracy of Class 54: 0.4560\nAccuracy of Class 55: 0.2680\nAccuracy of Class 56: 0.0760\nAccuracy of Class 57: 0.0400\nAccuracy of Class 58: 0.0200\nAccuracy of Class 59: 0.3520\nAccuracy of Class 60: 0.2240\nAccuracy of Class 61: 0.1560\nAccuracy of Class 62: 0.3000\nAccuracy of Class 63: 0.8080\nAccuracy of Class 64: 0.6720\nAccuracy of Class 65: 0.7200\nAccuracy of Class 66: 0.3000\nAccuracy of Class 67: 0.0520\nAccuracy of Class 68: 0.6560\nAccuracy of Class 69: 0.7080\nAccuracy of Class 70: 0.8840\nAccuracy of Class 71: 0.5000\nAccuracy of Class 72: 0.3640\nAccuracy of Class 73: 0.4120\nAccuracy of Class 74: 0.4720\nAccuracy of Class 75: 0.6480\nAccuracy of Class 76: 0.6280\nAccuracy of Class 77: 0.0760\nAccuracy of Class 78: 0.6240\nAccuracy of Class 79: 0.3800\nAccuracy of Class 80: 0.4840\nAccuracy of Class 81: 0.5880\nAccuracy of Class 82: 0.0120\nAccuracy of Class 83: 0.6240\nAccuracy of Class 84: 0.6760\nAccuracy of Class 85: 0.4400\nAccuracy of Class 86: 0.6560\nAccuracy of Class 87: 0.0840\nAccuracy of Class 88: 0.7760\nAccuracy of Class 89: 0.4280\nAccuracy of Class 90: 0.1800\nAccuracy of Class 91: 0.1200\nAccuracy of Class 92: 0.3320\nAccuracy of Class 93: 0.2200\nAccuracy of Class 94: 0.4960\nAccuracy of Class 95: 0.1800\nAccuracy of Class 96: 0.0840\nAccuracy of Class 97: 0.1480\nAccuracy of Class 98: 0.4640\nAccuracy of Class 99: 0.4280\nAccuracy of Class 100: 0.3480\n* Prec @1: 0.3952\nEpoch: [1][0/1184]\tTime 0.015 (0.015)\tLoss 2.5213 (2.5213)\tPrec @1 0.4062 (0.4062)\t\nEpoch: [1][10/1184]\tTime 0.907 (0.745)\tLoss 2.3413 (2.4400)\tPrec @1 0.4062 (0.4062)\t\nEpoch: [1][20/1184]\tTime 0.912 (0.780)\tLoss 2.3561 (2.3264)\tPrec @1 0.4375 (0.4196)\t\nEpoch: [1][30/1184]\tTime 0.907 (0.792)\tLoss 2.0304 (2.2618)\tPrec @1 0.4688 (0.4304)\t\nEpoch: [1][40/1184]\tTime 0.908 (0.799)\tLoss 2.0257 (2.1851)\tPrec @1 0.4844 (0.4501)\t\nEpoch: [1][50/1184]\tTime 0.908 (0.803)\tLoss 1.9473 (2.1425)\tPrec @1 0.5000 (0.4614)\t\nEpoch: [1][60/1184]\tTime 0.909 (0.806)\tLoss 1.8030 (2.1464)\tPrec @1 0.5781 (0.4593)\t\nEpoch: [1][70/1184]\tTime 0.913 (0.808)\tLoss 2.0739 (2.1246)\tPrec @1 0.4531 (0.4635)\t\nEpoch: [1][80/1184]\tTime 0.910 (0.809)\tLoss 1.9824 (2.1174)\tPrec @1 0.4219 (0.4655)\t\nEpoch: [1][90/1184]\tTime 0.907 (0.811)\tLoss 1.3990 (2.0835)\tPrec @1 0.6406 (0.4732)\t\nEpoch: [1][100/1184]\tTime 0.910 (0.812)\tLoss 1.9238 (2.0728)\tPrec @1 0.4688 (0.4762)\t\nEpoch: [1][110/1184]\tTime 0.922 (0.813)\tLoss 1.8502 (2.0513)\tPrec @1 0.4844 (0.4793)\t\nEpoch: [1][120/1184]\tTime 0.918 (0.814)\tLoss 1.9751 (2.0283)\tPrec @1 0.5312 (0.4854)\t\nEpoch: [1][130/1184]\tTime 0.911 (0.814)\tLoss 1.8265 (2.0136)\tPrec @1 0.5312 (0.4887)\t\nEpoch: [1][140/1184]\tTime 0.914 (0.815)\tLoss 1.8184 (2.0065)\tPrec @1 0.5469 (0.4893)\t\nEpoch: [1][150/1184]\tTime 0.909 (0.816)\tLoss 1.8077 (1.9942)\tPrec @1 0.4531 (0.4912)\t\nEpoch: [1][160/1184]\tTime 0.909 (0.816)\tLoss 1.5436 (1.9809)\tPrec @1 0.5469 (0.4942)\t\nEpoch: [1][170/1184]\tTime 0.914 (0.816)\tLoss 1.5045 (1.9737)\tPrec @1 0.5938 (0.4961)\t\nEpoch: [1][180/1184]\tTime 0.908 (0.816)\tLoss 1.4300 (1.9631)\tPrec @1 0.6562 (0.4999)\t\nEpoch: [1][190/1184]\tTime 0.910 (0.816)\tLoss 2.0601 (1.9525)\tPrec @1 0.4844 (0.5021)\t\nEpoch: [1][200/1184]\tTime 0.908 (0.817)\tLoss 2.1002 (1.9424)\tPrec @1 0.4219 (0.5038)\t\nEpoch: [1][210/1184]\tTime 0.909 (0.817)\tLoss 1.8675 (1.9333)\tPrec @1 0.4844 (0.5051)\t\nEpoch: [1][220/1184]\tTime 0.910 (0.817)\tLoss 1.5445 (1.9297)\tPrec @1 0.5469 (0.5066)\t\nEpoch: [1][230/1184]\tTime 0.910 (0.817)\tLoss 1.5569 (1.9245)\tPrec @1 0.5781 (0.5077)\t\nEpoch: [1][240/1184]\tTime 0.910 (0.817)\tLoss 2.0216 (1.9176)\tPrec @1 0.5156 (0.5091)\t\nEpoch: [1][250/1184]\tTime 0.925 (0.818)\tLoss 1.7635 (1.9187)\tPrec @1 0.5781 (0.5090)\t\nEpoch: [1][260/1184]\tTime 0.914 (0.818)\tLoss 1.6889 (1.9155)\tPrec @1 0.6562 (0.5100)\t\nEpoch: [1][270/1184]\tTime 0.911 (0.818)\tLoss 1.5971 (1.9101)\tPrec @1 0.5469 (0.5107)\t\nEpoch: [1][280/1184]\tTime 0.909 (0.818)\tLoss 1.8744 (1.9053)\tPrec @1 0.6094 (0.5123)\t\nEpoch: [1][290/1184]\tTime 0.910 (0.818)\tLoss 1.8570 (1.9054)\tPrec @1 0.5781 (0.5125)\t\nEpoch: [1][300/1184]\tTime 0.909 (0.818)\tLoss 1.3215 (1.8984)\tPrec @1 0.6250 (0.5145)\t\nEpoch: [1][310/1184]\tTime 0.909 (0.818)\tLoss 1.6864 (1.8901)\tPrec @1 0.5938 (0.5165)\t\nEpoch: [1][320/1184]\tTime 0.911 (0.818)\tLoss 1.4958 (1.8869)\tPrec @1 0.5625 (0.5165)\t\nEpoch: [1][330/1184]\tTime 0.909 (0.819)\tLoss 1.8873 (1.8836)\tPrec @1 0.5312 (0.5175)\t\nEpoch: [1][340/1184]\tTime 0.923 (0.819)\tLoss 1.3971 (1.8781)\tPrec @1 0.5781 (0.5178)\t\nEpoch: [1][350/1184]\tTime 0.921 (0.819)\tLoss 1.8032 (1.8727)\tPrec @1 0.5000 (0.5191)\t\nEpoch: [1][360/1184]\tTime 0.916 (0.819)\tLoss 1.5955 (1.8698)\tPrec @1 0.6250 (0.5193)\t\nEpoch: [1][370/1184]\tTime 0.917 (0.819)\tLoss 1.7496 (1.8676)\tPrec @1 0.4844 (0.5200)\t\nEpoch: [1][380/1184]\tTime 0.912 (0.819)\tLoss 1.7021 (1.8644)\tPrec @1 0.6094 (0.5216)\t\nEpoch: [1][390/1184]\tTime 0.911 (0.819)\tLoss 2.0567 (1.8607)\tPrec @1 0.4531 (0.5221)\t\nEpoch: [1][400/1184]\tTime 0.909 (0.819)\tLoss 1.7499 (1.8576)\tPrec @1 0.4844 (0.5223)\t\nEpoch: [1][410/1184]\tTime 0.906 (0.819)\tLoss 1.7237 (1.8531)\tPrec @1 0.5000 (0.5234)\t\nEpoch: [1][420/1184]\tTime 0.908 (0.819)\tLoss 2.1737 (1.8516)\tPrec @1 0.4688 (0.5238)\t\nEpoch: [1][430/1184]\tTime 0.914 (0.819)\tLoss 1.8238 (1.8488)\tPrec @1 0.5312 (0.5241)\t\nEpoch: [1][440/1184]\tTime 0.919 (0.820)\tLoss 1.1801 (1.8444)\tPrec @1 0.6875 (0.5250)\t\nEpoch: [1][450/1184]\tTime 0.911 (0.820)\tLoss 1.5821 (1.8405)\tPrec @1 0.6406 (0.5257)\t\nEpoch: [1][460/1184]\tTime 0.913 (0.820)\tLoss 1.6447 (1.8383)\tPrec @1 0.5938 (0.5265)\t\nEpoch: [1][470/1184]\tTime 0.911 (0.820)\tLoss 1.8119 (1.8363)\tPrec @1 0.5781 (0.5267)\t\nEpoch: [1][480/1184]\tTime 0.921 (0.820)\tLoss 2.0781 (1.8325)\tPrec @1 0.4688 (0.5280)\t\nEpoch: [1][490/1184]\tTime 0.917 (0.820)\tLoss 2.0571 (1.8291)\tPrec @1 0.4844 (0.5286)\t\nEpoch: [1][500/1184]\tTime 0.908 (0.820)\tLoss 1.7653 (1.8250)\tPrec @1 0.5312 (0.5295)\t\nEpoch: [1][510/1184]\tTime 0.910 (0.820)\tLoss 1.6188 (1.8226)\tPrec @1 0.5781 (0.5298)\t\nEpoch: [1][520/1184]\tTime 0.907 (0.820)\tLoss 1.8757 (1.8195)\tPrec @1 0.4531 (0.5302)\t\nEpoch: [1][530/1184]\tTime 0.909 (0.820)\tLoss 1.7149 (1.8168)\tPrec @1 0.5156 (0.5308)\t\nEpoch: [1][540/1184]\tTime 0.911 (0.820)\tLoss 1.4898 (1.8145)\tPrec @1 0.5781 (0.5314)\t\nEpoch: [1][550/1184]\tTime 0.914 (0.820)\tLoss 1.7260 (1.8126)\tPrec @1 0.5781 (0.5316)\t\nEpoch: [1][560/1184]\tTime 0.917 (0.820)\tLoss 1.7238 (1.8093)\tPrec @1 0.5312 (0.5322)\t\nEpoch: [1][570/1184]\tTime 0.923 (0.820)\tLoss 2.0593 (1.8082)\tPrec @1 0.5312 (0.5324)\t\nEpoch: [1][580/1184]\tTime 0.908 (0.820)\tLoss 1.8525 (1.8048)\tPrec @1 0.5625 (0.5333)\t\nEpoch: [1][590/1184]\tTime 0.910 (0.820)\tLoss 1.1598 (1.8017)\tPrec @1 0.6719 (0.5339)\t\nEpoch: [1][600/1184]\tTime 0.907 (0.820)\tLoss 1.7264 (1.8000)\tPrec @1 0.5625 (0.5339)\t\nEpoch: [1][610/1184]\tTime 0.911 (0.820)\tLoss 1.5233 (1.7983)\tPrec @1 0.5938 (0.5343)\t\nEpoch: [1][620/1184]\tTime 0.915 (0.821)\tLoss 1.4830 (1.7979)\tPrec @1 0.6406 (0.5346)\t\nEpoch: [1][630/1184]\tTime 0.909 (0.821)\tLoss 1.2382 (1.7961)\tPrec @1 0.6875 (0.5352)\t\nEpoch: [1][640/1184]\tTime 0.910 (0.821)\tLoss 1.8030 (1.7928)\tPrec @1 0.5938 (0.5356)\t\nEpoch: [1][650/1184]\tTime 0.920 (0.821)\tLoss 1.6010 (1.7914)\tPrec @1 0.6250 (0.5360)\t\nEpoch: [1][660/1184]\tTime 0.909 (0.821)\tLoss 1.8613 (1.7907)\tPrec @1 0.4531 (0.5360)\t\nEpoch: [1][670/1184]\tTime 0.911 (0.821)\tLoss 1.7034 (1.7884)\tPrec @1 0.5000 (0.5367)\t\nEpoch: [1][680/1184]\tTime 0.910 (0.821)\tLoss 2.3017 (1.7883)\tPrec @1 0.4688 (0.5368)\t\nEpoch: [1][690/1184]\tTime 0.922 (0.821)\tLoss 1.5317 (1.7882)\tPrec @1 0.5938 (0.5369)\t\nEpoch: [1][700/1184]\tTime 0.913 (0.821)\tLoss 1.7776 (1.7867)\tPrec @1 0.5156 (0.5374)\t\nEpoch: [1][710/1184]\tTime 0.914 (0.821)\tLoss 1.4018 (1.7851)\tPrec @1 0.5938 (0.5375)\t\nEpoch: [1][720/1184]\tTime 0.923 (0.821)\tLoss 1.8305 (1.7841)\tPrec @1 0.6094 (0.5378)\t\nEpoch: [1][730/1184]\tTime 0.908 (0.821)\tLoss 1.5609 (1.7819)\tPrec @1 0.5781 (0.5383)\t\nEpoch: [1][740/1184]\tTime 0.917 (0.821)\tLoss 1.5445 (1.7803)\tPrec @1 0.5938 (0.5387)\t\nEpoch: [1][750/1184]\tTime 0.912 (0.821)\tLoss 2.2753 (1.7784)\tPrec @1 0.4375 (0.5390)\t\nEpoch: [1][760/1184]\tTime 0.916 (0.821)\tLoss 1.5421 (1.7783)\tPrec @1 0.5938 (0.5391)\t\nEpoch: [1][770/1184]\tTime 0.912 (0.821)\tLoss 1.3527 (1.7760)\tPrec @1 0.5938 (0.5396)\t\nEpoch: [1][780/1184]\tTime 0.908 (0.821)\tLoss 1.9730 (1.7742)\tPrec @1 0.5625 (0.5403)\t\nEpoch: [1][790/1184]\tTime 0.921 (0.821)\tLoss 1.7789 (1.7731)\tPrec @1 0.5312 (0.5403)\t\nEpoch: [1][800/1184]\tTime 0.920 (0.821)\tLoss 2.0048 (1.7727)\tPrec @1 0.4688 (0.5404)\t\nEpoch: [1][810/1184]\tTime 0.912 (0.821)\tLoss 1.4812 (1.7708)\tPrec @1 0.5781 (0.5407)\t\nEpoch: [1][820/1184]\tTime 0.912 (0.821)\tLoss 2.0195 (1.7681)\tPrec @1 0.5000 (0.5413)\t\nEpoch: [1][830/1184]\tTime 0.915 (0.821)\tLoss 1.7656 (1.7664)\tPrec @1 0.5312 (0.5419)\t\nEpoch: [1][840/1184]\tTime 0.924 (0.821)\tLoss 2.0852 (1.7661)\tPrec @1 0.5156 (0.5422)\t\nEpoch: [1][850/1184]\tTime 0.922 (0.821)\tLoss 1.9743 (1.7637)\tPrec @1 0.5312 (0.5426)\t\nEpoch: [1][860/1184]\tTime 0.924 (0.821)\tLoss 1.5706 (1.7622)\tPrec @1 0.6250 (0.5431)\t\nEpoch: [1][870/1184]\tTime 0.923 (0.821)\tLoss 1.4851 (1.7612)\tPrec @1 0.5938 (0.5433)\t\nEpoch: [1][880/1184]\tTime 0.923 (0.822)\tLoss 1.7593 (1.7601)\tPrec @1 0.4688 (0.5435)\t\nEpoch: [1][890/1184]\tTime 0.917 (0.822)\tLoss 1.9064 (1.7587)\tPrec @1 0.5000 (0.5437)\t\nEpoch: [1][900/1184]\tTime 0.918 (0.822)\tLoss 1.2853 (1.7581)\tPrec @1 0.6562 (0.5439)\t\nEpoch: [1][910/1184]\tTime 0.922 (0.822)\tLoss 1.5250 (1.7571)\tPrec @1 0.6250 (0.5442)\t\nEpoch: [1][920/1184]\tTime 0.924 (0.822)\tLoss 1.7962 (1.7558)\tPrec @1 0.5312 (0.5444)\t\nEpoch: [1][930/1184]\tTime 0.920 (0.822)\tLoss 1.8745 (1.7544)\tPrec @1 0.5469 (0.5448)\t\nEpoch: [1][940/1184]\tTime 0.923 (0.822)\tLoss 1.4414 (1.7530)\tPrec @1 0.5625 (0.5449)\t\nEpoch: [1][950/1184]\tTime 0.912 (0.822)\tLoss 2.1091 (1.7519)\tPrec @1 0.5312 (0.5450)\t\nEpoch: [1][960/1184]\tTime 0.916 (0.822)\tLoss 1.5253 (1.7496)\tPrec @1 0.5938 (0.5458)\t\nEpoch: [1][970/1184]\tTime 0.918 (0.822)\tLoss 1.5355 (1.7484)\tPrec @1 0.6094 (0.5460)\t\nEpoch: [1][980/1184]\tTime 0.923 (0.822)\tLoss 2.0247 (1.7474)\tPrec @1 0.5469 (0.5462)\t\nEpoch: [1][990/1184]\tTime 0.913 (0.822)\tLoss 1.6067 (1.7451)\tPrec @1 0.6719 (0.5469)\t\nEpoch: [1][1000/1184]\tTime 0.915 (0.822)\tLoss 1.5237 (1.7446)\tPrec @1 0.5625 (0.5469)\t\nEpoch: [1][1010/1184]\tTime 0.916 (0.822)\tLoss 1.3670 (1.7425)\tPrec @1 0.5469 (0.5473)\t\nEpoch: [1][1020/1184]\tTime 0.912 (0.822)\tLoss 1.5954 (1.7414)\tPrec @1 0.6562 (0.5475)\t\nEpoch: [1][1030/1184]\tTime 0.911 (0.822)\tLoss 1.4149 (1.7386)\tPrec @1 0.6094 (0.5479)\t\nEpoch: [1][1040/1184]\tTime 0.926 (0.822)\tLoss 1.7751 (1.7374)\tPrec @1 0.5625 (0.5484)\t\nEpoch: [1][1050/1184]\tTime 0.924 (0.822)\tLoss 1.6632 (1.7366)\tPrec @1 0.5625 (0.5484)\t\nEpoch: [1][1060/1184]\tTime 0.926 (0.823)\tLoss 1.5651 (1.7353)\tPrec @1 0.5781 (0.5486)\t\nEpoch: [1][1070/1184]\tTime 0.914 (0.823)\tLoss 1.6113 (1.7339)\tPrec @1 0.5781 (0.5489)\t\nEpoch: [1][1080/1184]\tTime 0.911 (0.823)\tLoss 1.9596 (1.7332)\tPrec @1 0.5156 (0.5492)\t\nEpoch: [1][1090/1184]\tTime 0.923 (0.823)\tLoss 1.6157 (1.7330)\tPrec @1 0.5781 (0.5492)\t\nEpoch: [1][1100/1184]\tTime 0.922 (0.823)\tLoss 1.6262 (1.7311)\tPrec @1 0.6250 (0.5498)\t\nEpoch: [1][1110/1184]\tTime 0.914 (0.823)\tLoss 1.3307 (1.7288)\tPrec @1 0.6094 (0.5503)\t\nEpoch: [1][1120/1184]\tTime 0.912 (0.823)\tLoss 1.5976 (1.7282)\tPrec @1 0.5781 (0.5503)\t\nEpoch: [1][1130/1184]\tTime 0.915 (0.823)\tLoss 1.7700 (1.7267)\tPrec @1 0.5156 (0.5508)\t\nEpoch: [1][1140/1184]\tTime 0.917 (0.823)\tLoss 1.7983 (1.7263)\tPrec @1 0.5312 (0.5510)\t\nEpoch: [1][1150/1184]\tTime 0.924 (0.823)\tLoss 1.8820 (1.7248)\tPrec @1 0.5156 (0.5514)\t\nEpoch: [1][1160/1184]\tTime 0.926 (0.823)\tLoss 1.4775 (1.7231)\tPrec @1 0.6406 (0.5518)\t\nEpoch: [1][1170/1184]\tTime 0.922 (0.823)\tLoss 1.4236 (1.7225)\tPrec @1 0.6250 (0.5520)\t\nEpoch: [1][1180/1184]\tTime 0.912 (0.823)\tLoss 1.5287 (1.7202)\tPrec @1 0.5625 (0.5526)\t\n\n*** WARNING: skipped 85241 bytes of output ***\n\nEpoch: [7][800/1184]\tTime 0.925 (0.827)\tLoss 1.4588 (1.4023)\tPrec @1 0.6250 (0.6276)\t\nEpoch: [7][810/1184]\tTime 0.925 (0.827)\tLoss 1.3086 (1.4015)\tPrec @1 0.5625 (0.6277)\t\nEpoch: [7][820/1184]\tTime 0.921 (0.827)\tLoss 1.1783 (1.3997)\tPrec @1 0.6875 (0.6279)\t\nEpoch: [7][830/1184]\tTime 0.926 (0.827)\tLoss 1.3781 (1.3991)\tPrec @1 0.6406 (0.6280)\t\nEpoch: [7][840/1184]\tTime 0.928 (0.827)\tLoss 1.3308 (1.3986)\tPrec @1 0.6875 (0.6284)\t\nEpoch: [7][850/1184]\tTime 0.927 (0.827)\tLoss 1.5640 (1.3979)\tPrec @1 0.7031 (0.6289)\t\nEpoch: [7][860/1184]\tTime 0.918 (0.827)\tLoss 0.7992 (1.3967)\tPrec @1 0.7969 (0.6293)\t\nEpoch: [7][870/1184]\tTime 0.919 (0.827)\tLoss 1.9279 (1.3979)\tPrec @1 0.4531 (0.6289)\t\nEpoch: [7][880/1184]\tTime 0.927 (0.827)\tLoss 1.4714 (1.3967)\tPrec @1 0.5938 (0.6289)\t\nEpoch: [7][890/1184]\tTime 0.925 (0.827)\tLoss 1.1074 (1.3968)\tPrec @1 0.6875 (0.6288)\t\nEpoch: [7][900/1184]\tTime 0.923 (0.828)\tLoss 1.2036 (1.3970)\tPrec @1 0.6406 (0.6284)\t\nEpoch: [7][910/1184]\tTime 0.928 (0.828)\tLoss 1.1780 (1.3968)\tPrec @1 0.6875 (0.6285)\t\nEpoch: [7][920/1184]\tTime 0.928 (0.828)\tLoss 1.1643 (1.3980)\tPrec @1 0.6719 (0.6282)\t\nEpoch: [7][930/1184]\tTime 0.916 (0.828)\tLoss 0.8978 (1.3973)\tPrec @1 0.7344 (0.6283)\t\nEpoch: [7][940/1184]\tTime 0.921 (0.828)\tLoss 1.4307 (1.3981)\tPrec @1 0.6250 (0.6281)\t\nEpoch: [7][950/1184]\tTime 0.925 (0.828)\tLoss 1.5222 (1.3992)\tPrec @1 0.6094 (0.6277)\t\nEpoch: [7][960/1184]\tTime 0.924 (0.828)\tLoss 1.9139 (1.3996)\tPrec @1 0.4688 (0.6277)\t\nEpoch: [7][970/1184]\tTime 0.916 (0.828)\tLoss 1.2985 (1.3998)\tPrec @1 0.6406 (0.6276)\t\nEpoch: [7][980/1184]\tTime 0.925 (0.828)\tLoss 1.5436 (1.4001)\tPrec @1 0.5469 (0.6276)\t\nEpoch: [7][990/1184]\tTime 0.929 (0.828)\tLoss 1.5700 (1.3997)\tPrec @1 0.6250 (0.6277)\t\nEpoch: [7][1000/1184]\tTime 0.924 (0.828)\tLoss 1.1448 (1.3992)\tPrec @1 0.7500 (0.6279)\t\nEpoch: [7][1010/1184]\tTime 0.927 (0.828)\tLoss 1.4056 (1.4004)\tPrec @1 0.6406 (0.6274)\t\nEpoch: [7][1020/1184]\tTime 0.924 (0.828)\tLoss 1.4327 (1.4004)\tPrec @1 0.6562 (0.6274)\t\nEpoch: [7][1030/1184]\tTime 0.917 (0.828)\tLoss 1.6481 (1.3996)\tPrec @1 0.5625 (0.6275)\t\nEpoch: [7][1040/1184]\tTime 0.927 (0.828)\tLoss 1.5136 (1.3993)\tPrec @1 0.5938 (0.6276)\t\nEpoch: [7][1050/1184]\tTime 0.918 (0.828)\tLoss 1.0485 (1.3982)\tPrec @1 0.6875 (0.6279)\t\nEpoch: [7][1060/1184]\tTime 0.924 (0.828)\tLoss 1.3607 (1.3977)\tPrec @1 0.6719 (0.6280)\t\nEpoch: [7][1070/1184]\tTime 0.926 (0.828)\tLoss 1.3291 (1.3972)\tPrec @1 0.6719 (0.6283)\t\nEpoch: [7][1080/1184]\tTime 0.918 (0.828)\tLoss 1.4832 (1.3973)\tPrec @1 0.5938 (0.6284)\t\nEpoch: [7][1090/1184]\tTime 0.915 (0.828)\tLoss 1.4078 (1.3969)\tPrec @1 0.6875 (0.6282)\t\nEpoch: [7][1100/1184]\tTime 0.925 (0.828)\tLoss 1.4276 (1.3976)\tPrec @1 0.6562 (0.6281)\t\nEpoch: [7][1110/1184]\tTime 0.924 (0.828)\tLoss 1.1024 (1.3968)\tPrec @1 0.6562 (0.6284)\t\nEpoch: [7][1120/1184]\tTime 0.925 (0.828)\tLoss 1.4250 (1.3966)\tPrec @1 0.6719 (0.6284)\t\nEpoch: [7][1130/1184]\tTime 0.919 (0.828)\tLoss 1.1090 (1.3966)\tPrec @1 0.6875 (0.6284)\t\nEpoch: [7][1140/1184]\tTime 0.923 (0.828)\tLoss 1.4172 (1.3966)\tPrec @1 0.6562 (0.6286)\t\nEpoch: [7][1150/1184]\tTime 0.923 (0.828)\tLoss 1.4111 (1.3962)\tPrec @1 0.5781 (0.6286)\t\nEpoch: [7][1160/1184]\tTime 0.915 (0.828)\tLoss 1.5937 (1.3980)\tPrec @1 0.5625 (0.6282)\t\nEpoch: [7][1170/1184]\tTime 0.921 (0.828)\tLoss 1.3468 (1.3977)\tPrec @1 0.6562 (0.6282)\t\nEpoch: [7][1180/1184]\tTime 0.914 (0.828)\tLoss 1.2190 (1.3976)\tPrec @1 0.6719 (0.6281)\t\nEpoch: [7][0/395]\tTime 0.284 (0.284)\t\nEpoch: [7][10/395]\tTime 0.296 (0.291)\t\nEpoch: [7][20/395]\tTime 0.285 (0.291)\t\nEpoch: [7][30/395]\tTime 0.287 (0.290)\t\nEpoch: [7][40/395]\tTime 0.285 (0.290)\t\nEpoch: [7][50/395]\tTime 0.286 (0.290)\t\nEpoch: [7][60/395]\tTime 0.286 (0.289)\t\nEpoch: [7][70/395]\tTime 0.292 (0.289)\t\nEpoch: [7][80/395]\tTime 0.282 (0.288)\t\nEpoch: [7][90/395]\tTime 0.286 (0.289)\t\nEpoch: [7][100/395]\tTime 0.283 (0.288)\t\nEpoch: [7][110/395]\tTime 0.289 (0.288)\t\nEpoch: [7][120/395]\tTime 0.293 (0.288)\t\nEpoch: [7][130/395]\tTime 0.288 (0.288)\t\nEpoch: [7][140/395]\tTime 0.293 (0.289)\t\nEpoch: [7][150/395]\tTime 0.285 (0.288)\t\nEpoch: [7][160/395]\tTime 0.292 (0.288)\t\nEpoch: [7][170/395]\tTime 0.287 (0.288)\t\nEpoch: [7][180/395]\tTime 0.294 (0.288)\t\nEpoch: [7][190/395]\tTime 0.285 (0.288)\t\nEpoch: [7][200/395]\tTime 0.280 (0.288)\t\nEpoch: [7][210/395]\tTime 0.284 (0.288)\t\nEpoch: [7][220/395]\tTime 0.284 (0.288)\t\nEpoch: [7][230/395]\tTime 0.293 (0.288)\t\nEpoch: [7][240/395]\tTime 0.284 (0.288)\t\nEpoch: [7][250/395]\tTime 0.293 (0.288)\t\nEpoch: [7][260/395]\tTime 0.282 (0.288)\t\nEpoch: [7][270/395]\tTime 0.293 (0.288)\t\nEpoch: [7][280/395]\tTime 0.282 (0.288)\t\nEpoch: [7][290/395]\tTime 0.291 (0.288)\t\nEpoch: [7][300/395]\tTime 0.282 (0.288)\t\nEpoch: [7][310/395]\tTime 0.293 (0.288)\t\nEpoch: [7][320/395]\tTime 0.288 (0.288)\t\nEpoch: [7][330/395]\tTime 0.297 (0.288)\t\nEpoch: [7][340/395]\tTime 0.290 (0.288)\t\nEpoch: [7][350/395]\tTime 0.279 (0.288)\t\nEpoch: [7][360/395]\tTime 0.285 (0.288)\t\nEpoch: [7][370/395]\tTime 0.286 (0.288)\t\nEpoch: [7][380/395]\tTime 0.284 (0.288)\t\nEpoch: [7][390/395]\tTime 0.283 (0.288)\t\nAccuracy of Class 0: 0.2400\nAccuracy of Class 1: 0.6000\nAccuracy of Class 2: 0.7240\nAccuracy of Class 3: 0.7720\nAccuracy of Class 4: 0.6760\nAccuracy of Class 5: 0.5280\nAccuracy of Class 6: 0.8240\nAccuracy of Class 7: 0.8040\nAccuracy of Class 8: 0.4240\nAccuracy of Class 9: 0.3080\nAccuracy of Class 10: 0.5880\nAccuracy of Class 11: 0.7880\nAccuracy of Class 12: 0.6080\nAccuracy of Class 13: 0.6760\nAccuracy of Class 14: 0.7080\nAccuracy of Class 15: 0.4080\nAccuracy of Class 16: 0.6960\nAccuracy of Class 17: 0.4760\nAccuracy of Class 18: 0.3400\nAccuracy of Class 19: 0.6240\nAccuracy of Class 20: 0.7280\nAccuracy of Class 21: 0.6680\nAccuracy of Class 22: 0.3080\nAccuracy of Class 23: 0.7640\nAccuracy of Class 24: 0.7880\nAccuracy of Class 25: 0.7640\nAccuracy of Class 26: 0.5400\nAccuracy of Class 27: 0.7360\nAccuracy of Class 28: 0.7640\nAccuracy of Class 29: 0.7600\nAccuracy of Class 30: 0.8560\nAccuracy of Class 31: 0.6760\nAccuracy of Class 32: 0.8560\nAccuracy of Class 33: 0.9880\nAccuracy of Class 34: 0.7640\nAccuracy of Class 35: 0.7520\nAccuracy of Class 36: 0.5400\nAccuracy of Class 37: 0.4640\nAccuracy of Class 38: 0.7680\nAccuracy of Class 39: 0.3520\nAccuracy of Class 40: 0.8720\nAccuracy of Class 41: 0.7040\nAccuracy of Class 42: 0.5680\nAccuracy of Class 43: 0.7400\nAccuracy of Class 44: 0.7200\nAccuracy of Class 45: 0.7800\nAccuracy of Class 46: 0.5760\nAccuracy of Class 47: 0.3960\nAccuracy of Class 48: 0.6600\nAccuracy of Class 49: 0.4920\nAccuracy of Class 50: 0.3640\nAccuracy of Class 51: 0.8680\nAccuracy of Class 52: 0.6600\nAccuracy of Class 53: 0.6280\nAccuracy of Class 54: 0.8720\nAccuracy of Class 55: 0.6480\nAccuracy of Class 56: 0.2840\nAccuracy of Class 57: 0.4240\nAccuracy of Class 58: 0.4800\nAccuracy of Class 59: 0.4760\nAccuracy of Class 60: 0.7880\nAccuracy of Class 61: 0.6400\nAccuracy of Class 62: 0.5840\nAccuracy of Class 63: 0.9080\nAccuracy of Class 64: 0.8200\nAccuracy of Class 65: 0.8160\nAccuracy of Class 66: 0.4120\nAccuracy of Class 67: 0.2520\nAccuracy of Class 68: 0.8320\nAccuracy of Class 69: 0.8600\nAccuracy of Class 70: 0.8160\nAccuracy of Class 71: 0.6760\nAccuracy of Class 72: 0.7160\nAccuracy of Class 73: 0.5400\nAccuracy of Class 74: 0.5800\nAccuracy of Class 75: 0.8440\nAccuracy of Class 76: 0.8000\nAccuracy of Class 77: 0.4040\nAccuracy of Class 78: 0.7360\nAccuracy of Class 79: 0.7520\nAccuracy of Class 80: 0.6520\nAccuracy of Class 81: 0.6280\nAccuracy of Class 82: 0.3200\nAccuracy of Class 83: 0.8240\nAccuracy of Class 84: 0.5480\nAccuracy of Class 85: 0.5400\nAccuracy of Class 86: 0.7880\nAccuracy of Class 87: 0.5200\nAccuracy of Class 88: 0.8800\nAccuracy of Class 89: 0.5200\nAccuracy of Class 90: 0.7960\nAccuracy of Class 91: 0.8560\nAccuracy of Class 92: 0.6160\nAccuracy of Class 93: 0.2920\nAccuracy of Class 94: 0.6840\nAccuracy of Class 95: 0.6480\nAccuracy of Class 96: 0.3920\nAccuracy of Class 97: 0.7040\nAccuracy of Class 98: 0.5920\nAccuracy of Class 99: 0.4520\nAccuracy of Class 100: 0.7560\n* Prec @1: 0.6400\nEpoch: [8][0/1184]\tTime 0.015 (0.015)\tLoss 1.4933 (1.4933)\tPrec @1 0.5781 (0.5781)\t\nEpoch: [8][10/1184]\tTime 0.910 (0.745)\tLoss 1.6592 (1.4271)\tPrec @1 0.5938 (0.6207)\t\nEpoch: [8][20/1184]\tTime 0.919 (0.781)\tLoss 1.5517 (1.3773)\tPrec @1 0.5625 (0.6272)\t\nEpoch: [8][30/1184]\tTime 0.914 (0.795)\tLoss 1.4972 (1.4142)\tPrec @1 0.6250 (0.6220)\t\nEpoch: [8][40/1184]\tTime 0.912 (0.802)\tLoss 1.4851 (1.3965)\tPrec @1 0.6719 (0.6261)\t\nEpoch: [8][50/1184]\tTime 0.914 (0.807)\tLoss 1.7679 (1.4049)\tPrec @1 0.5781 (0.6256)\t\nEpoch: [8][60/1184]\tTime 0.910 (0.810)\tLoss 1.4717 (1.3939)\tPrec @1 0.5469 (0.6255)\t\nEpoch: [8][70/1184]\tTime 0.913 (0.812)\tLoss 1.3237 (1.3923)\tPrec @1 0.6094 (0.6276)\t\nEpoch: [8][80/1184]\tTime 0.923 (0.814)\tLoss 1.6889 (1.4004)\tPrec @1 0.5469 (0.6267)\t\nEpoch: [8][90/1184]\tTime 0.921 (0.815)\tLoss 1.9576 (1.4046)\tPrec @1 0.4531 (0.6248)\t\nEpoch: [8][100/1184]\tTime 0.922 (0.816)\tLoss 1.5020 (1.4009)\tPrec @1 0.5938 (0.6267)\t\nEpoch: [8][110/1184]\tTime 0.914 (0.817)\tLoss 1.5619 (1.3980)\tPrec @1 0.5781 (0.6263)\t\nEpoch: [8][120/1184]\tTime 0.909 (0.818)\tLoss 1.2937 (1.3896)\tPrec @1 0.6406 (0.6278)\t\nEpoch: [8][130/1184]\tTime 0.909 (0.818)\tLoss 1.1595 (1.3964)\tPrec @1 0.6719 (0.6264)\t\nEpoch: [8][140/1184]\tTime 0.911 (0.818)\tLoss 0.9821 (1.3972)\tPrec @1 0.7500 (0.6266)\t\nEpoch: [8][150/1184]\tTime 0.919 (0.818)\tLoss 1.2420 (1.3960)\tPrec @1 0.6250 (0.6272)\t\nEpoch: [8][160/1184]\tTime 0.911 (0.819)\tLoss 0.9818 (1.3908)\tPrec @1 0.6719 (0.6277)\t\nEpoch: [8][170/1184]\tTime 0.923 (0.819)\tLoss 1.3086 (1.3883)\tPrec @1 0.6562 (0.6285)\t\nEpoch: [8][180/1184]\tTime 0.911 (0.819)\tLoss 1.6762 (1.3897)\tPrec @1 0.5156 (0.6285)\t\nEpoch: [8][190/1184]\tTime 0.913 (0.820)\tLoss 1.3843 (1.3919)\tPrec @1 0.6406 (0.6283)\t\nEpoch: [8][200/1184]\tTime 0.918 (0.820)\tLoss 1.4318 (1.3853)\tPrec @1 0.5469 (0.6291)\t\nEpoch: [8][210/1184]\tTime 0.910 (0.820)\tLoss 1.5662 (1.3909)\tPrec @1 0.6094 (0.6285)\t\nEpoch: [8][220/1184]\tTime 0.919 (0.820)\tLoss 1.3013 (1.3872)\tPrec @1 0.5938 (0.6294)\t\nEpoch: [8][230/1184]\tTime 0.912 (0.821)\tLoss 1.4854 (1.3898)\tPrec @1 0.6250 (0.6291)\t\nEpoch: [8][240/1184]\tTime 0.908 (0.821)\tLoss 1.3463 (1.3932)\tPrec @1 0.6094 (0.6282)\t\nEpoch: [8][250/1184]\tTime 0.910 (0.821)\tLoss 1.0431 (1.3923)\tPrec @1 0.7344 (0.6287)\t\nEpoch: [8][260/1184]\tTime 0.923 (0.821)\tLoss 1.3914 (1.3925)\tPrec @1 0.7031 (0.6294)\t\nEpoch: [8][270/1184]\tTime 0.922 (0.821)\tLoss 1.6800 (1.3918)\tPrec @1 0.5312 (0.6293)\t\nEpoch: [8][280/1184]\tTime 0.913 (0.821)\tLoss 1.5795 (1.3909)\tPrec @1 0.5938 (0.6289)\t\nEpoch: [8][290/1184]\tTime 0.911 (0.821)\tLoss 1.4503 (1.3927)\tPrec @1 0.5781 (0.6284)\t\nEpoch: [8][300/1184]\tTime 0.910 (0.822)\tLoss 1.0160 (1.3937)\tPrec @1 0.7656 (0.6283)\t\nEpoch: [8][310/1184]\tTime 0.911 (0.822)\tLoss 1.5191 (1.3948)\tPrec @1 0.5938 (0.6280)\t\nEpoch: [8][320/1184]\tTime 0.913 (0.822)\tLoss 1.1810 (1.3915)\tPrec @1 0.6875 (0.6291)\t\nEpoch: [8][330/1184]\tTime 0.911 (0.822)\tLoss 1.2287 (1.3916)\tPrec @1 0.7031 (0.6288)\t\nEpoch: [8][340/1184]\tTime 0.916 (0.822)\tLoss 1.3266 (1.3880)\tPrec @1 0.6562 (0.6301)\t\nEpoch: [8][350/1184]\tTime 0.912 (0.822)\tLoss 1.0752 (1.3900)\tPrec @1 0.6094 (0.6298)\t\nEpoch: [8][360/1184]\tTime 0.909 (0.822)\tLoss 1.3054 (1.3897)\tPrec @1 0.6406 (0.6297)\t\nEpoch: [8][370/1184]\tTime 0.919 (0.822)\tLoss 1.6858 (1.3903)\tPrec @1 0.5156 (0.6294)\t\nEpoch: [8][380/1184]\tTime 0.914 (0.822)\tLoss 1.1612 (1.3891)\tPrec @1 0.7031 (0.6292)\t\nEpoch: [8][390/1184]\tTime 0.923 (0.822)\tLoss 0.8963 (1.3912)\tPrec @1 0.7344 (0.6288)\t\nEpoch: [8][400/1184]\tTime 0.925 (0.822)\tLoss 1.4378 (1.3912)\tPrec @1 0.5781 (0.6286)\t\nEpoch: [8][410/1184]\tTime 0.923 (0.822)\tLoss 1.3741 (1.3929)\tPrec @1 0.6094 (0.6280)\t\nEpoch: [8][420/1184]\tTime 0.921 (0.822)\tLoss 1.3541 (1.3933)\tPrec @1 0.5625 (0.6272)\t\nEpoch: [8][430/1184]\tTime 0.916 (0.822)\tLoss 1.6693 (1.3925)\tPrec @1 0.5469 (0.6276)\t\nEpoch: [8][440/1184]\tTime 0.921 (0.822)\tLoss 1.0799 (1.3955)\tPrec @1 0.6875 (0.6270)\t\nEpoch: [8][450/1184]\tTime 0.910 (0.822)\tLoss 1.2894 (1.3965)\tPrec @1 0.6250 (0.6264)\t\nEpoch: [8][460/1184]\tTime 0.922 (0.822)\tLoss 1.3501 (1.3970)\tPrec @1 0.6406 (0.6264)\t\nEpoch: [8][470/1184]\tTime 0.908 (0.822)\tLoss 1.5970 (1.3973)\tPrec @1 0.5469 (0.6263)\t\nEpoch: [8][480/1184]\tTime 0.911 (0.822)\tLoss 1.5963 (1.3982)\tPrec @1 0.5312 (0.6261)\t\nEpoch: [8][490/1184]\tTime 0.920 (0.822)\tLoss 1.2002 (1.3966)\tPrec @1 0.6562 (0.6259)\t\nEpoch: [8][500/1184]\tTime 0.909 (0.822)\tLoss 1.6898 (1.3974)\tPrec @1 0.5625 (0.6255)\t\nEpoch: [8][510/1184]\tTime 0.909 (0.822)\tLoss 1.3903 (1.3961)\tPrec @1 0.5781 (0.6258)\t\nEpoch: [8][520/1184]\tTime 0.908 (0.822)\tLoss 1.0656 (1.3952)\tPrec @1 0.6719 (0.6259)\t\nEpoch: [8][530/1184]\tTime 0.919 (0.822)\tLoss 1.3612 (1.3959)\tPrec @1 0.5938 (0.6255)\t\nEpoch: [8][540/1184]\tTime 0.912 (0.823)\tLoss 1.1521 (1.3963)\tPrec @1 0.6406 (0.6254)\t\nEpoch: [8][550/1184]\tTime 0.924 (0.823)\tLoss 1.4319 (1.3978)\tPrec @1 0.5781 (0.6250)\t\nEpoch: [8][560/1184]\tTime 0.923 (0.823)\tLoss 1.4037 (1.3979)\tPrec @1 0.6562 (0.6253)\t\nEpoch: [8][570/1184]\tTime 0.916 (0.823)\tLoss 1.9574 (1.3986)\tPrec @1 0.5312 (0.6250)\t\nEpoch: [8][580/1184]\tTime 0.915 (0.823)\tLoss 1.8138 (1.3998)\tPrec @1 0.5312 (0.6248)\t\nEpoch: [8][590/1184]\tTime 0.921 (0.823)\tLoss 1.5484 (1.3990)\tPrec @1 0.6250 (0.6250)\t\nEpoch: [8][600/1184]\tTime 0.923 (0.823)\tLoss 1.4341 (1.4014)\tPrec @1 0.6250 (0.6247)\t\nEpoch: [8][610/1184]\tTime 0.910 (0.823)\tLoss 1.2782 (1.4029)\tPrec @1 0.5938 (0.6244)\t\nEpoch: [8][620/1184]\tTime 0.909 (0.823)\tLoss 1.0234 (1.4028)\tPrec @1 0.7344 (0.6241)\t\nEpoch: [8][630/1184]\tTime 0.907 (0.823)\tLoss 1.3544 (1.4029)\tPrec @1 0.5469 (0.6240)\t\nEpoch: [8][640/1184]\tTime 0.922 (0.823)\tLoss 1.2378 (1.4012)\tPrec @1 0.6406 (0.6244)\t\nEpoch: [8][650/1184]\tTime 0.908 (0.823)\tLoss 1.1775 (1.4010)\tPrec @1 0.7031 (0.6246)\t\nEpoch: [8][660/1184]\tTime 0.909 (0.823)\tLoss 1.3259 (1.3995)\tPrec @1 0.6562 (0.6249)\t\nEpoch: [8][670/1184]\tTime 0.910 (0.823)\tLoss 1.3464 (1.3997)\tPrec @1 0.6094 (0.6249)\t\nEpoch: [8][680/1184]\tTime 0.915 (0.823)\tLoss 1.6946 (1.3998)\tPrec @1 0.5625 (0.6248)\t\nEpoch: [8][690/1184]\tTime 0.909 (0.823)\tLoss 1.0999 (1.4000)\tPrec @1 0.7188 (0.6249)\t\nEpoch: [8][700/1184]\tTime 0.908 (0.823)\tLoss 1.3363 (1.3992)\tPrec @1 0.6094 (0.6250)\t\nEpoch: [8][710/1184]\tTime 0.914 (0.823)\tLoss 1.4870 (1.3994)\tPrec @1 0.5938 (0.6250)\t\nEpoch: [8][720/1184]\tTime 0.915 (0.823)\tLoss 1.4023 (1.3984)\tPrec @1 0.6250 (0.6251)\t\nEpoch: [8][730/1184]\tTime 0.910 (0.823)\tLoss 1.6486 (1.3975)\tPrec @1 0.5469 (0.6252)\t\nEpoch: [8][740/1184]\tTime 0.913 (0.823)\tLoss 1.6509 (1.3989)\tPrec @1 0.5156 (0.6247)\t\nEpoch: [8][750/1184]\tTime 0.921 (0.823)\tLoss 1.2970 (1.3975)\tPrec @1 0.6406 (0.6250)\t\nEpoch: [8][760/1184]\tTime 0.913 (0.823)\tLoss 1.7055 (1.3968)\tPrec @1 0.5625 (0.6253)\t\nEpoch: [8][770/1184]\tTime 0.918 (0.823)\tLoss 1.0934 (1.3969)\tPrec @1 0.6875 (0.6256)\t\nEpoch: [8][780/1184]\tTime 0.921 (0.823)\tLoss 1.1929 (1.3958)\tPrec @1 0.6719 (0.6258)\t\nEpoch: [8][790/1184]\tTime 0.922 (0.823)\tLoss 1.0958 (1.3966)\tPrec @1 0.6719 (0.6259)\t\nEpoch: [8][800/1184]\tTime 0.911 (0.823)\tLoss 1.4007 (1.3979)\tPrec @1 0.7344 (0.6258)\t\nEpoch: [8][810/1184]\tTime 0.913 (0.823)\tLoss 1.2299 (1.3983)\tPrec @1 0.6562 (0.6257)\t\nEpoch: [8][820/1184]\tTime 0.921 (0.823)\tLoss 1.4845 (1.3988)\tPrec @1 0.5938 (0.6254)\t\nEpoch: [8][830/1184]\tTime 0.908 (0.823)\tLoss 1.8158 (1.3978)\tPrec @1 0.6250 (0.6261)\t\nEpoch: [8][840/1184]\tTime 0.921 (0.823)\tLoss 1.4386 (1.3978)\tPrec @1 0.6250 (0.6262)\t\nEpoch: [8][850/1184]\tTime 0.912 (0.823)\tLoss 1.6095 (1.3981)\tPrec @1 0.5781 (0.6263)\t\nEpoch: [8][860/1184]\tTime 0.913 (0.823)\tLoss 1.3736 (1.3978)\tPrec @1 0.6406 (0.6265)\t\nEpoch: [8][870/1184]\tTime 0.910 (0.823)\tLoss 1.1984 (1.3983)\tPrec @1 0.6875 (0.6261)\t\nEpoch: [8][880/1184]\tTime 0.921 (0.823)\tLoss 1.1112 (1.3981)\tPrec @1 0.6875 (0.6262)\t\nEpoch: [8][890/1184]\tTime 0.911 (0.823)\tLoss 1.3684 (1.3975)\tPrec @1 0.5781 (0.6262)\t\nEpoch: [8][900/1184]\tTime 0.921 (0.823)\tLoss 1.4731 (1.3970)\tPrec @1 0.6094 (0.6264)\t\nEpoch: [8][910/1184]\tTime 0.922 (0.823)\tLoss 1.0405 (1.3957)\tPrec @1 0.6875 (0.6267)\t\nEpoch: [8][920/1184]\tTime 0.915 (0.823)\tLoss 1.7765 (1.3966)\tPrec @1 0.6094 (0.6265)\t\nEpoch: [8][930/1184]\tTime 0.911 (0.823)\tLoss 1.4774 (1.3964)\tPrec @1 0.6094 (0.6266)\t\nEpoch: [8][940/1184]\tTime 0.920 (0.823)\tLoss 1.5412 (1.3962)\tPrec @1 0.6094 (0.6265)\t\nEpoch: [8][950/1184]\tTime 0.914 (0.823)\tLoss 1.4045 (1.3957)\tPrec @1 0.7188 (0.6268)\t\nEpoch: [8][960/1184]\tTime 0.912 (0.823)\tLoss 1.1479 (1.3954)\tPrec @1 0.7188 (0.6271)\t\nEpoch: [8][970/1184]\tTime 0.920 (0.823)\tLoss 1.7132 (1.3967)\tPrec @1 0.6250 (0.6269)\t\nEpoch: [8][980/1184]\tTime 0.923 (0.823)\tLoss 1.7740 (1.3975)\tPrec @1 0.6250 (0.6269)\t\nEpoch: [8][990/1184]\tTime 0.910 (0.823)\tLoss 1.1075 (1.3979)\tPrec @1 0.6094 (0.6268)\t\nEpoch: [8][1000/1184]\tTime 0.912 (0.823)\tLoss 1.4579 (1.3975)\tPrec @1 0.5938 (0.6270)\t\nEpoch: [8][1010/1184]\tTime 0.921 (0.823)\tLoss 1.4378 (1.3970)\tPrec @1 0.5625 (0.6272)\t\nEpoch: [8][1020/1184]\tTime 0.914 (0.823)\tLoss 1.1243 (1.3964)\tPrec @1 0.7031 (0.6275)\t\nEpoch: [8][1030/1184]\tTime 0.923 (0.823)\tLoss 1.2745 (1.3958)\tPrec @1 0.6719 (0.6274)\t\nEpoch: [8][1040/1184]\tTime 0.924 (0.823)\tLoss 1.1498 (1.3964)\tPrec @1 0.5938 (0.6271)\t\nEpoch: [8][1050/1184]\tTime 0.921 (0.823)\tLoss 1.6545 (1.3961)\tPrec @1 0.5469 (0.6272)\t\nEpoch: [8][1060/1184]\tTime 0.921 (0.823)\tLoss 1.4441 (1.3962)\tPrec @1 0.5469 (0.6274)\t\nEpoch: [8][1070/1184]\tTime 0.923 (0.823)\tLoss 1.2439 (1.3971)\tPrec @1 0.6250 (0.6272)\t\nEpoch: [8][1080/1184]\tTime 0.913 (0.823)\tLoss 1.3063 (1.3966)\tPrec @1 0.6250 (0.6271)\t\nEpoch: [8][1090/1184]\tTime 0.923 (0.823)\tLoss 1.3264 (1.3966)\tPrec @1 0.5938 (0.6270)\t\nEpoch: [8][1100/1184]\tTime 0.911 (0.823)\tLoss 1.3361 (1.3970)\tPrec @1 0.7031 (0.6269)\t\nEpoch: [8][1110/1184]\tTime 0.924 (0.823)\tLoss 1.7777 (1.3977)\tPrec @1 0.5312 (0.6268)\t\nEpoch: [8][1120/1184]\tTime 0.913 (0.823)\tLoss 1.6313 (1.3978)\tPrec @1 0.6094 (0.6268)\t\nEpoch: [8][1130/1184]\tTime 0.924 (0.823)\tLoss 1.5138 (1.3969)\tPrec @1 0.6094 (0.6269)\t\nEpoch: [8][1140/1184]\tTime 0.921 (0.823)\tLoss 1.4782 (1.3972)\tPrec @1 0.6250 (0.6269)\t\nEpoch: [8][1150/1184]\tTime 0.922 (0.824)\tLoss 1.8960 (1.3977)\tPrec @1 0.5469 (0.6269)\t\nEpoch: [8][1160/1184]\tTime 0.925 (0.824)\tLoss 1.3476 (1.3972)\tPrec @1 0.6562 (0.6270)\t\nEpoch: [8][1170/1184]\tTime 0.914 (0.824)\tLoss 1.0692 (1.3974)\tPrec @1 0.6719 (0.6268)\t\nEpoch: [8][1180/1184]\tTime 0.922 (0.824)\tLoss 1.3973 (1.3978)\tPrec @1 0.6094 (0.6268)\t\nEpoch: [8][0/395]\tTime 0.283 (0.283)\t\nEpoch: [8][10/395]\tTime 0.297 (0.291)\t\nEpoch: [8][20/395]\tTime 0.284 (0.290)\t\nEpoch: [8][30/395]\tTime 0.286 (0.290)\t\nEpoch: [8][40/395]\tTime 0.280 (0.290)\t\nEpoch: [8][50/395]\tTime 0.282 (0.289)\t\nEpoch: [8][60/395]\tTime 0.295 (0.289)\t\nEpoch: [8][70/395]\tTime 0.280 (0.288)\t\nEpoch: [8][80/395]\tTime 0.296 (0.288)\t\nEpoch: [8][90/395]\tTime 0.284 (0.288)\t\nEpoch: [8][100/395]\tTime 0.292 (0.288)\t\nEpoch: [8][110/395]\tTime 0.280 (0.288)\t\nEpoch: [8][120/395]\tTime 0.289 (0.288)\t\nEpoch: [8][130/395]\tTime 0.285 (0.288)\t\nEpoch: [8][140/395]\tTime 0.298 (0.288)\t\nEpoch: [8][150/395]\tTime 0.287 (0.288)\t\nEpoch: [8][160/395]\tTime 0.291 (0.288)\t\nEpoch: [8][170/395]\tTime 0.291 (0.288)\t\nEpoch: [8][180/395]\tTime 0.295 (0.289)\t\nEpoch: [8][190/395]\tTime 0.287 (0.289)\t\nEpoch: [8][200/395]\tTime 0.296 (0.289)\t\nEpoch: [8][210/395]\tTime 0.286 (0.289)\t\nEpoch: [8][220/395]\tTime 0.295 (0.289)\t\nEpoch: [8][230/395]\tTime 0.290 (0.289)\t\nEpoch: [8][240/395]\tTime 0.298 (0.289)\t\nEpoch: [8][250/395]\tTime 0.289 (0.289)\t\nEpoch: [8][260/395]\tTime 0.282 (0.289)\t\nEpoch: [8][270/395]\tTime 0.288 (0.288)\t\nEpoch: [8][280/395]\tTime 0.288 (0.288)\t\nEpoch: [8][290/395]\tTime 0.299 (0.288)\t\nEpoch: [8][300/395]\tTime 0.285 (0.288)\t\nEpoch: [8][310/395]\tTime 0.290 (0.288)\t\nEpoch: [8][320/395]\tTime 0.282 (0.288)\t\nEpoch: [8][330/395]\tTime 0.286 (0.288)\t\nEpoch: [8][340/395]\tTime 0.287 (0.288)\t\nEpoch: [8][350/395]\tTime 0.297 (0.288)\t\nEpoch: [8][360/395]\tTime 0.292 (0.288)\t\nEpoch: [8][370/395]\tTime 0.297 (0.288)\t\nEpoch: [8][380/395]\tTime 0.285 (0.288)\t\nEpoch: [8][390/395]\tTime 0.286 (0.288)\t\nAccuracy of Class 0: 0.2400\nAccuracy of Class 1: 0.6280\nAccuracy of Class 2: 0.6880\nAccuracy of Class 3: 0.7600\nAccuracy of Class 4: 0.6520\nAccuracy of Class 5: 0.5200\nAccuracy of Class 6: 0.8320\nAccuracy of Class 7: 0.8000\nAccuracy of Class 8: 0.3840\nAccuracy of Class 9: 0.3280\nAccuracy of Class 10: 0.5640\nAccuracy of Class 11: 0.7680\nAccuracy of Class 12: 0.6200\nAccuracy of Class 13: 0.6800\nAccuracy of Class 14: 0.6760\nAccuracy of Class 15: 0.3960\nAccuracy of Class 16: 0.6800\nAccuracy of Class 17: 0.4840\nAccuracy of Class 18: 0.3720\nAccuracy of Class 19: 0.6440\nAccuracy of Class 20: 0.7320\nAccuracy of Class 21: 0.6400\nAccuracy of Class 22: 0.3440\nAccuracy of Class 23: 0.7680\nAccuracy of Class 24: 0.7680\nAccuracy of Class 25: 0.7440\nAccuracy of Class 26: 0.5320\nAccuracy of Class 27: 0.7320\nAccuracy of Class 28: 0.7640\nAccuracy of Class 29: 0.7760\nAccuracy of Class 30: 0.8520\nAccuracy of Class 31: 0.6520\nAccuracy of Class 32: 0.8600\nAccuracy of Class 33: 0.9880\nAccuracy of Class 34: 0.7520\nAccuracy of Class 35: 0.7720\nAccuracy of Class 36: 0.5720\nAccuracy of Class 37: 0.4520\nAccuracy of Class 38: 0.7640\nAccuracy of Class 39: 0.3680\nAccuracy of Class 40: 0.8080\nAccuracy of Class 41: 0.6880\nAccuracy of Class 42: 0.5840\nAccuracy of Class 43: 0.7360\nAccuracy of Class 44: 0.7560\nAccuracy of Class 45: 0.7400\nAccuracy of Class 46: 0.5600\nAccuracy of Class 47: 0.4200\nAccuracy of Class 48: 0.6640\nAccuracy of Class 49: 0.4880\nAccuracy of Class 50: 0.3680\nAccuracy of Class 51: 0.8720\nAccuracy of Class 52: 0.6800\nAccuracy of Class 53: 0.6000\nAccuracy of Class 54: 0.8960\nAccuracy of Class 55: 0.6320\nAccuracy of Class 56: 0.3120\nAccuracy of Class 57: 0.3880\nAccuracy of Class 58: 0.5240\nAccuracy of Class 59: 0.4560\nAccuracy of Class 60: 0.8000\nAccuracy of Class 61: 0.6600\nAccuracy of Class 62: 0.5880\nAccuracy of Class 63: 0.9000\nAccuracy of Class 64: 0.8120\nAccuracy of Class 65: 0.8240\nAccuracy of Class 66: 0.4080\nAccuracy of Class 67: 0.2560\nAccuracy of Class 68: 0.8640\nAccuracy of Class 69: 0.8600\nAccuracy of Class 70: 0.8160\nAccuracy of Class 71: 0.6640\nAccuracy of Class 72: 0.7200\nAccuracy of Class 73: 0.5720\nAccuracy of Class 74: 0.5960\nAccuracy of Class 75: 0.8240\nAccuracy of Class 76: 0.7800\nAccuracy of Class 77: 0.3840\nAccuracy of Class 78: 0.7360\nAccuracy of Class 79: 0.7600\nAccuracy of Class 80: 0.5840\nAccuracy of Class 81: 0.6120\nAccuracy of Class 82: 0.3080\nAccuracy of Class 83: 0.8400\nAccuracy of Class 84: 0.5240\nAccuracy of Class 85: 0.5680\nAccuracy of Class 86: 0.7920\nAccuracy of Class 87: 0.5240\nAccuracy of Class 88: 0.8680\nAccuracy of Class 89: 0.5960\nAccuracy of Class 90: 0.8000\nAccuracy of Class 91: 0.8400\nAccuracy of Class 92: 0.6160\nAccuracy of Class 93: 0.2800\nAccuracy of Class 94: 0.7000\nAccuracy of Class 95: 0.6000\nAccuracy of Class 96: 0.3960\nAccuracy of Class 97: 0.6560\nAccuracy of Class 98: 0.6200\nAccuracy of Class 99: 0.4240\nAccuracy of Class 100: 0.7480\n* Prec @1: 0.6380\nEpoch: [9][0/1184]\tTime 0.020 (0.020)\tLoss 1.1665 (1.1665)\tPrec @1 0.6250 (0.6250)\t\nEpoch: [9][10/1184]\tTime 0.908 (0.746)\tLoss 1.1685 (1.2492)\tPrec @1 0.7188 (0.6676)\t\nEpoch: [9][20/1184]\tTime 0.910 (0.782)\tLoss 1.3092 (1.3178)\tPrec @1 0.6875 (0.6443)\t\nEpoch: [9][30/1184]\tTime 0.914 (0.796)\tLoss 1.2506 (1.3192)\tPrec @1 0.6562 (0.6436)\t\nEpoch: [9][40/1184]\tTime 0.923 (0.803)\tLoss 1.4425 (1.3207)\tPrec @1 0.6094 (0.6425)\t\nEpoch: [9][50/1184]\tTime 0.923 (0.808)\tLoss 1.6119 (1.3558)\tPrec @1 0.6406 (0.6348)\t\nEpoch: [9][60/1184]\tTime 0.925 (0.811)\tLoss 1.0558 (1.3500)\tPrec @1 0.6875 (0.6363)\t\nEpoch: [9][70/1184]\tTime 0.914 (0.814)\tLoss 1.4036 (1.3629)\tPrec @1 0.6094 (0.6340)\t\nEpoch: [9][80/1184]\tTime 0.925 (0.816)\tLoss 1.5756 (1.3619)\tPrec @1 0.5469 (0.6333)\t\nEpoch: [9][90/1184]\tTime 0.921 (0.817)\tLoss 1.3613 (1.3679)\tPrec @1 0.6562 (0.6331)\t\nEpoch: [9][100/1184]\tTime 0.923 (0.818)\tLoss 1.6621 (1.3819)\tPrec @1 0.5469 (0.6298)\t\nEpoch: [9][110/1184]\tTime 0.923 (0.819)\tLoss 1.5338 (1.3819)\tPrec @1 0.6094 (0.6295)\t\nEpoch: [9][120/1184]\tTime 0.922 (0.820)\tLoss 1.1525 (1.3844)\tPrec @1 0.7188 (0.6306)\t\nEpoch: [9][130/1184]\tTime 0.923 (0.820)\tLoss 1.1953 (1.3851)\tPrec @1 0.6250 (0.6300)\t\nEpoch: [9][140/1184]\tTime 0.923 (0.821)\tLoss 1.0229 (1.3883)\tPrec @1 0.6562 (0.6295)\t\nEpoch: [9][150/1184]\tTime 0.911 (0.821)\tLoss 1.3207 (1.3911)\tPrec @1 0.6094 (0.6281)\t\nEpoch: [9][160/1184]\tTime 0.924 (0.822)\tLoss 1.8704 (1.3886)\tPrec @1 0.6250 (0.6293)\t\nEpoch: [9][170/1184]\tTime 0.917 (0.822)\tLoss 1.4975 (1.3914)\tPrec @1 0.5938 (0.6289)\t\nEpoch: [9][180/1184]\tTime 0.926 (0.822)\tLoss 1.2343 (1.3880)\tPrec @1 0.6562 (0.6309)\t\nEpoch: [9][190/1184]\tTime 0.917 (0.823)\tLoss 1.5068 (1.3873)\tPrec @1 0.6250 (0.6306)\t\nEpoch: [9][200/1184]\tTime 0.923 (0.823)\tLoss 1.1634 (1.3944)\tPrec @1 0.6875 (0.6290)\t\nEpoch: [9][210/1184]\tTime 0.924 (0.823)\tLoss 1.4787 (1.3947)\tPrec @1 0.6719 (0.6289)\t\nEpoch: [9][220/1184]\tTime 0.922 (0.823)\tLoss 1.2879 (1.3972)\tPrec @1 0.6562 (0.6278)\t\nEpoch: [9][230/1184]\tTime 0.920 (0.824)\tLoss 1.2508 (1.3964)\tPrec @1 0.6250 (0.6283)\t\nEpoch: [9][240/1184]\tTime 0.926 (0.824)\tLoss 1.3471 (1.3994)\tPrec @1 0.6406 (0.6274)\t\nEpoch: [9][250/1184]\tTime 0.926 (0.824)\tLoss 1.4752 (1.4050)\tPrec @1 0.5781 (0.6266)\t\nEpoch: [9][260/1184]\tTime 0.921 (0.824)\tLoss 1.3937 (1.4082)\tPrec @1 0.6719 (0.6257)\t\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Epoch: [0][0/1184]\tTime 0.035 (0.035)\tLoss 4.6255 (4.6255)\tPrec @1 0.0312 (0.0312)\t\nEpoch: [0][10/1184]\tTime 0.855 (0.702)\tLoss 4.6506 (4.6169)\tPrec @1 0.0000 (0.0156)\t\nEpoch: [0][20/1184]\tTime 0.861 (0.737)\tLoss 4.5632 (4.6097)\tPrec @1 0.0156 (0.0149)\t\nEpoch: [0][30/1184]\tTime 0.867 (0.750)\tLoss 4.5064 (4.5805)\tPrec @1 0.0312 (0.0202)\t\nEpoch: [0][40/1184]\tTime 0.868 (0.758)\tLoss 4.4831 (4.5591)\tPrec @1 0.0625 (0.0267)\t\nEpoch: [0][50/1184]\tTime 0.874 (0.763)\tLoss 4.4054 (4.5419)\tPrec @1 0.0312 (0.0270)\t\nEpoch: [0][60/1184]\tTime 0.879 (0.768)\tLoss 4.2485 (4.5141)\tPrec @1 0.0625 (0.0295)\t\nEpoch: [0][70/1184]\tTime 0.884 (0.771)\tLoss 4.2441 (4.4631)\tPrec @1 0.0938 (0.0363)\t\nEpoch: [0][80/1184]\tTime 0.887 (0.775)\tLoss 3.9830 (4.4208)\tPrec @1 0.0469 (0.0411)\t\nEpoch: [0][90/1184]\tTime 0.891 (0.777)\tLoss 3.8274 (4.3870)\tPrec @1 0.1250 (0.0452)\t\nEpoch: [0][100/1184]\tTime 0.901 (0.783)\tLoss 4.0999 (4.3502)\tPrec @1 0.0625 (0.0476)\t\nEpoch: [0][110/1184]\tTime 0.888 (0.784)\tLoss 3.9097 (4.3165)\tPrec @1 0.0625 (0.0511)\t\nEpoch: [0][120/1184]\tTime 0.888 (0.786)\tLoss 4.0645 (4.2923)\tPrec @1 0.0625 (0.0540)\t\nEpoch: [0][130/1184]\tTime 0.901 (0.788)\tLoss 4.1812 (4.2641)\tPrec @1 0.0312 (0.0568)\t\nEpoch: [0][140/1184]\tTime 0.905 (0.789)\tLoss 3.4618 (4.2329)\tPrec @1 0.1719 (0.0609)\t\nEpoch: [0][150/1184]\tTime 0.901 (0.791)\tLoss 3.7848 (4.2008)\tPrec @1 0.1094 (0.0662)\t\nEpoch: [0][160/1184]\tTime 0.907 (0.792)\tLoss 3.9122 (4.1703)\tPrec @1 0.0781 (0.0689)\t\nEpoch: [0][170/1184]\tTime 0.910 (0.794)\tLoss 3.5266 (4.1367)\tPrec @1 0.1719 (0.0736)\t\nEpoch: [0][180/1184]\tTime 0.909 (0.795)\tLoss 3.9242 (4.1080)\tPrec @1 0.0625 (0.0780)\t\nEpoch: [0][190/1184]\tTime 0.906 (0.796)\tLoss 3.7460 (4.0838)\tPrec @1 0.1719 (0.0813)\t\nEpoch: [0][200/1184]\tTime 0.906 (0.797)\tLoss 3.5774 (4.0570)\tPrec @1 0.1094 (0.0855)\t\nEpoch: [0][210/1184]\tTime 0.906 (0.798)\tLoss 2.9064 (4.0320)\tPrec @1 0.3438 (0.0889)\t\nEpoch: [0][220/1184]\tTime 0.907 (0.799)\tLoss 3.6764 (4.0166)\tPrec @1 0.0312 (0.0914)\t\nEpoch: [0][230/1184]\tTime 0.910 (0.800)\tLoss 3.9623 (3.9995)\tPrec @1 0.1094 (0.0947)\t\nEpoch: [0][240/1184]\tTime 0.911 (0.801)\tLoss 3.7852 (3.9888)\tPrec @1 0.1562 (0.0969)\t\nEpoch: [0][250/1184]\tTime 0.911 (0.802)\tLoss 3.2099 (3.9666)\tPrec @1 0.2031 (0.1005)\t\nEpoch: [0][260/1184]\tTime 0.908 (0.802)\tLoss 3.4049 (3.9494)\tPrec @1 0.1406 (0.1028)\t\nEpoch: [0][270/1184]\tTime 0.905 (0.803)\tLoss 3.1229 (3.9286)\tPrec @1 0.2500 (0.1064)\t\nEpoch: [0][280/1184]\tTime 0.906 (0.803)\tLoss 3.5374 (3.9086)\tPrec @1 0.1250 (0.1090)\t\nEpoch: [0][290/1184]\tTime 0.919 (0.804)\tLoss 3.6359 (3.8962)\tPrec @1 0.1719 (0.1122)\t\nEpoch: [0][300/1184]\tTime 0.913 (0.805)\tLoss 3.7685 (3.8838)\tPrec @1 0.1094 (0.1140)\t\nEpoch: [0][310/1184]\tTime 0.911 (0.805)\tLoss 3.5900 (3.8724)\tPrec @1 0.1250 (0.1156)\t\nEpoch: [0][320/1184]\tTime 0.911 (0.806)\tLoss 2.9778 (3.8543)\tPrec @1 0.2344 (0.1183)\t\nEpoch: [0][330/1184]\tTime 0.921 (0.806)\tLoss 3.6571 (3.8420)\tPrec @1 0.1250 (0.1205)\t\nEpoch: [0][340/1184]\tTime 0.908 (0.807)\tLoss 3.4196 (3.8282)\tPrec @1 0.1875 (0.1226)\t\nEpoch: [0][350/1184]\tTime 0.909 (0.807)\tLoss 3.0921 (3.8126)\tPrec @1 0.2500 (0.1249)\t\nEpoch: [0][360/1184]\tTime 0.919 (0.807)\tLoss 2.8594 (3.7953)\tPrec @1 0.2656 (0.1280)\t\nEpoch: [0][370/1184]\tTime 0.908 (0.808)\tLoss 3.5253 (3.7814)\tPrec @1 0.1875 (0.1301)\t\nEpoch: [0][380/1184]\tTime 0.910 (0.808)\tLoss 3.1436 (3.7658)\tPrec @1 0.2969 (0.1331)\t\nEpoch: [0][390/1184]\tTime 0.911 (0.809)\tLoss 3.2317 (3.7502)\tPrec @1 0.1875 (0.1362)\t\nEpoch: [0][400/1184]\tTime 0.909 (0.809)\tLoss 3.6256 (3.7383)\tPrec @1 0.1094 (0.1382)\t\nEpoch: [0][410/1184]\tTime 0.911 (0.809)\tLoss 2.9443 (3.7258)\tPrec @1 0.2969 (0.1406)\t\nEpoch: [0][420/1184]\tTime 0.914 (0.810)\tLoss 3.0577 (3.7144)\tPrec @1 0.2812 (0.1428)\t\nEpoch: [0][430/1184]\tTime 0.912 (0.810)\tLoss 2.7955 (3.7014)\tPrec @1 0.2969 (0.1448)\t\nEpoch: [0][440/1184]\tTime 0.914 (0.810)\tLoss 3.2757 (3.6885)\tPrec @1 0.2656 (0.1472)\t\nEpoch: [0][450/1184]\tTime 0.911 (0.811)\tLoss 2.7152 (3.6733)\tPrec @1 0.2656 (0.1500)\t\nEpoch: [0][460/1184]\tTime 0.909 (0.811)\tLoss 2.8739 (3.6632)\tPrec @1 0.3281 (0.1517)\t\nEpoch: [0][470/1184]\tTime 0.912 (0.811)\tLoss 2.6857 (3.6509)\tPrec @1 0.2969 (0.1539)\t\nEpoch: [0][480/1184]\tTime 0.908 (0.811)\tLoss 2.7424 (3.6383)\tPrec @1 0.3750 (0.1559)\t\nEpoch: [0][490/1184]\tTime 0.910 (0.812)\tLoss 2.8291 (3.6253)\tPrec @1 0.2344 (0.1578)\t\nEpoch: [0][500/1184]\tTime 0.914 (0.812)\tLoss 3.2637 (3.6164)\tPrec @1 0.1875 (0.1593)\t\nEpoch: [0][510/1184]\tTime 0.908 (0.812)\tLoss 2.7588 (3.6044)\tPrec @1 0.2656 (0.1612)\t\nEpoch: [0][520/1184]\tTime 0.911 (0.812)\tLoss 2.6348 (3.5916)\tPrec @1 0.3125 (0.1633)\t\nEpoch: [0][530/1184]\tTime 0.910 (0.812)\tLoss 3.2222 (3.5802)\tPrec @1 0.2344 (0.1650)\t\nEpoch: [0][540/1184]\tTime 0.908 (0.812)\tLoss 2.7243 (3.5699)\tPrec @1 0.2812 (0.1666)\t\nEpoch: [0][550/1184]\tTime 0.919 (0.813)\tLoss 2.6078 (3.5585)\tPrec @1 0.3281 (0.1688)\t\nEpoch: [0][560/1184]\tTime 0.916 (0.813)\tLoss 2.6823 (3.5452)\tPrec @1 0.4062 (0.1712)\t\nEpoch: [0][570/1184]\tTime 0.919 (0.813)\tLoss 3.2582 (3.5402)\tPrec @1 0.1875 (0.1721)\t\nEpoch: [0][580/1184]\tTime 0.921 (0.813)\tLoss 3.0288 (3.5319)\tPrec @1 0.2188 (0.1738)\t\nEpoch: [0][590/1184]\tTime 0.921 (0.813)\tLoss 3.2648 (3.5237)\tPrec @1 0.2031 (0.1750)\t\nEpoch: [0][600/1184]\tTime 0.911 (0.813)\tLoss 2.8146 (3.5117)\tPrec @1 0.2812 (0.1772)\t\nEpoch: [0][610/1184]\tTime 0.909 (0.814)\tLoss 3.1244 (3.5015)\tPrec @1 0.2969 (0.1792)\t\nEpoch: [0][620/1184]\tTime 0.911 (0.814)\tLoss 3.5229 (3.4951)\tPrec @1 0.1875 (0.1804)\t\nEpoch: [0][630/1184]\tTime 0.910 (0.814)\tLoss 3.3933 (3.4869)\tPrec @1 0.1875 (0.1818)\t\nEpoch: [0][640/1184]\tTime 0.912 (0.814)\tLoss 2.9906 (3.4784)\tPrec @1 0.2188 (0.1831)\t\nEpoch: [0][650/1184]\tTime 0.921 (0.814)\tLoss 2.8607 (3.4708)\tPrec @1 0.2969 (0.1844)\t\nEpoch: [0][660/1184]\tTime 0.909 (0.814)\tLoss 2.9139 (3.4619)\tPrec @1 0.2812 (0.1862)\t\nEpoch: [0][670/1184]\tTime 0.913 (0.814)\tLoss 2.6917 (3.4543)\tPrec @1 0.2812 (0.1875)\t\nEpoch: [0][680/1184]\tTime 0.909 (0.815)\tLoss 2.5046 (3.4445)\tPrec @1 0.4062 (0.1893)\t\nEpoch: [0][690/1184]\tTime 0.909 (0.815)\tLoss 2.4694 (3.4348)\tPrec @1 0.3594 (0.1915)\t\nEpoch: [0][700/1184]\tTime 0.923 (0.815)\tLoss 3.1343 (3.4283)\tPrec @1 0.2500 (0.1925)\t\nEpoch: [0][710/1184]\tTime 0.923 (0.815)\tLoss 3.1320 (3.4200)\tPrec @1 0.3281 (0.1939)\t\nEpoch: [0][720/1184]\tTime 0.908 (0.815)\tLoss 2.4213 (3.4105)\tPrec @1 0.3438 (0.1952)\t\nEpoch: [0][730/1184]\tTime 0.913 (0.815)\tLoss 2.8053 (3.4036)\tPrec @1 0.2812 (0.1962)\t\nEpoch: [0][740/1184]\tTime 0.909 (0.815)\tLoss 2.9226 (3.3966)\tPrec @1 0.2969 (0.1972)\t\nEpoch: [0][750/1184]\tTime 0.910 (0.815)\tLoss 2.6565 (3.3884)\tPrec @1 0.3281 (0.1985)\t\nEpoch: [0][760/1184]\tTime 0.909 (0.815)\tLoss 2.7720 (3.3809)\tPrec @1 0.2656 (0.1997)\t\nEpoch: [0][770/1184]\tTime 0.907 (0.815)\tLoss 2.3973 (3.3731)\tPrec @1 0.4062 (0.2011)\t\nEpoch: [0][780/1184]\tTime 0.906 (0.815)\tLoss 2.7160 (3.3654)\tPrec @1 0.2812 (0.2023)\t\nEpoch: [0][790/1184]\tTime 0.909 (0.816)\tLoss 3.2068 (3.3587)\tPrec @1 0.2188 (0.2034)\t\nEpoch: [0][800/1184]\tTime 0.909 (0.816)\tLoss 2.8783 (3.3507)\tPrec @1 0.2812 (0.2048)\t\nEpoch: [0][810/1184]\tTime 0.908 (0.816)\tLoss 2.8588 (3.3436)\tPrec @1 0.2500 (0.2059)\t\nEpoch: [0][820/1184]\tTime 0.910 (0.816)\tLoss 2.7791 (3.3354)\tPrec @1 0.2969 (0.2077)\t\nEpoch: [0][830/1184]\tTime 0.908 (0.816)\tLoss 2.7995 (3.3296)\tPrec @1 0.2969 (0.2087)\t\nEpoch: [0][840/1184]\tTime 0.912 (0.816)\tLoss 2.6748 (3.3234)\tPrec @1 0.3750 (0.2098)\t\nEpoch: [0][850/1184]\tTime 0.908 (0.816)\tLoss 2.6020 (3.3174)\tPrec @1 0.3438 (0.2111)\t\nEpoch: [0][860/1184]\tTime 0.907 (0.816)\tLoss 2.8461 (3.3121)\tPrec @1 0.2969 (0.2120)\t\nEpoch: [0][870/1184]\tTime 0.913 (0.816)\tLoss 3.7709 (3.3071)\tPrec @1 0.1719 (0.2131)\t\nEpoch: [0][880/1184]\tTime 0.923 (0.816)\tLoss 3.0221 (3.3019)\tPrec @1 0.2500 (0.2142)\t\nEpoch: [0][890/1184]\tTime 0.919 (0.816)\tLoss 2.7369 (3.2970)\tPrec @1 0.3594 (0.2149)\t\nEpoch: [0][900/1184]\tTime 0.921 (0.816)\tLoss 2.5622 (3.2908)\tPrec @1 0.3594 (0.2162)\t\nEpoch: [0][910/1184]\tTime 0.909 (0.816)\tLoss 2.8604 (3.2843)\tPrec @1 0.2500 (0.2172)\t\nEpoch: [0][920/1184]\tTime 0.915 (0.816)\tLoss 2.9386 (3.2765)\tPrec @1 0.3281 (0.2186)\t\nEpoch: [0][930/1184]\tTime 0.921 (0.816)\tLoss 2.5872 (3.2698)\tPrec @1 0.3438 (0.2202)\t\nEpoch: [0][940/1184]\tTime 0.910 (0.817)\tLoss 2.5199 (3.2632)\tPrec @1 0.3281 (0.2214)\t\nEpoch: [0][950/1184]\tTime 0.915 (0.817)\tLoss 3.0609 (3.2578)\tPrec @1 0.2500 (0.2225)\t\nEpoch: [0][960/1184]\tTime 0.910 (0.817)\tLoss 3.0064 (3.2530)\tPrec @1 0.2500 (0.2234)\t\nEpoch: [0][970/1184]\tTime 0.909 (0.817)\tLoss 2.7867 (3.2492)\tPrec @1 0.2812 (0.2241)\t\nEpoch: [0][980/1184]\tTime 0.909 (0.817)\tLoss 2.5705 (3.2434)\tPrec @1 0.4219 (0.2252)\t\nEpoch: [0][990/1184]\tTime 0.907 (0.817)\tLoss 3.5240 (3.2394)\tPrec @1 0.1250 (0.2256)\t\nEpoch: [0][1000/1184]\tTime 0.911 (0.817)\tLoss 3.0254 (3.2345)\tPrec @1 0.2500 (0.2267)\t\nEpoch: [0][1010/1184]\tTime 0.908 (0.817)\tLoss 2.8754 (3.2315)\tPrec @1 0.3750 (0.2275)\t\nEpoch: [0][1020/1184]\tTime 0.908 (0.817)\tLoss 2.4845 (3.2265)\tPrec @1 0.4219 (0.2286)\t\nEpoch: [0][1030/1184]\tTime 0.910 (0.817)\tLoss 2.3622 (3.2208)\tPrec @1 0.3594 (0.2298)\t\nEpoch: [0][1040/1184]\tTime 0.908 (0.817)\tLoss 2.6029 (3.2143)\tPrec @1 0.3125 (0.2310)\t\nEpoch: [0][1050/1184]\tTime 0.908 (0.817)\tLoss 2.7962 (3.2092)\tPrec @1 0.2812 (0.2316)\t\nEpoch: [0][1060/1184]\tTime 0.910 (0.817)\tLoss 3.1267 (3.2040)\tPrec @1 0.2812 (0.2329)\t\nEpoch: [0][1070/1184]\tTime 0.911 (0.817)\tLoss 2.9330 (3.1983)\tPrec @1 0.2812 (0.2338)\t\nEpoch: [0][1080/1184]\tTime 0.914 (0.817)\tLoss 3.3649 (3.1943)\tPrec @1 0.1719 (0.2347)\t\nEpoch: [0][1090/1184]\tTime 0.907 (0.817)\tLoss 1.9671 (3.1889)\tPrec @1 0.4844 (0.2357)\t\nEpoch: [0][1100/1184]\tTime 0.908 (0.817)\tLoss 2.4981 (3.1841)\tPrec @1 0.3438 (0.2364)\t\nEpoch: [0][1110/1184]\tTime 0.908 (0.817)\tLoss 2.6305 (3.1791)\tPrec @1 0.3125 (0.2373)\t\nEpoch: [0][1120/1184]\tTime 0.910 (0.817)\tLoss 2.4979 (3.1740)\tPrec @1 0.3750 (0.2383)\t\nEpoch: [0][1130/1184]\tTime 0.910 (0.817)\tLoss 2.4649 (3.1681)\tPrec @1 0.3750 (0.2393)\t\nEpoch: [0][1140/1184]\tTime 0.911 (0.817)\tLoss 2.0926 (3.1619)\tPrec @1 0.4688 (0.2405)\t\nEpoch: [0][1150/1184]\tTime 0.909 (0.817)\tLoss 2.6112 (3.1563)\tPrec @1 0.3438 (0.2416)\t\nEpoch: [0][1160/1184]\tTime 0.907 (0.817)\tLoss 2.6732 (3.1521)\tPrec @1 0.2812 (0.2424)\t\nEpoch: [0][1170/1184]\tTime 0.910 (0.817)\tLoss 2.3972 (3.1462)\tPrec @1 0.3594 (0.2437)\t\nEpoch: [0][1180/1184]\tTime 0.908 (0.817)\tLoss 2.7266 (3.1415)\tPrec @1 0.2969 (0.2446)\t\nEpoch: [0][0/395]\tTime 0.282 (0.282)\t\nEpoch: [0][10/395]\tTime 0.286 (0.286)\t\nEpoch: [0][20/395]\tTime 0.282 (0.287)\t\nEpoch: [0][30/395]\tTime 0.292 (0.287)\t\nEpoch: [0][40/395]\tTime 0.285 (0.288)\t\nEpoch: [0][50/395]\tTime 0.286 (0.288)\t\nEpoch: [0][60/395]\tTime 0.281 (0.288)\t\nEpoch: [0][70/395]\tTime 0.302 (0.288)\t\nEpoch: [0][80/395]\tTime 0.286 (0.288)\t\nEpoch: [0][90/395]\tTime 0.291 (0.288)\t\nEpoch: [0][100/395]\tTime 0.293 (0.288)\t\nEpoch: [0][110/395]\tTime 0.290 (0.288)\t\nEpoch: [0][120/395]\tTime 0.294 (0.288)\t\nEpoch: [0][130/395]\tTime 0.286 (0.288)\t\nEpoch: [0][140/395]\tTime 0.298 (0.288)\t\nEpoch: [0][150/395]\tTime 0.289 (0.288)\t\nEpoch: [0][160/395]\tTime 0.293 (0.288)\t\nEpoch: [0][170/395]\tTime 0.286 (0.288)\t\nEpoch: [0][180/395]\tTime 0.291 (0.288)\t\nEpoch: [0][190/395]\tTime 0.286 (0.288)\t\nEpoch: [0][200/395]\tTime 0.284 (0.288)\t\nEpoch: [0][210/395]\tTime 0.284 (0.288)\t\nEpoch: [0][220/395]\tTime 0.281 (0.288)\t\nEpoch: [0][230/395]\tTime 0.285 (0.288)\t\nEpoch: [0][240/395]\tTime 0.290 (0.288)\t\nEpoch: [0][250/395]\tTime 0.285 (0.288)\t\nEpoch: [0][260/395]\tTime 0.284 (0.288)\t\nEpoch: [0][270/395]\tTime 0.293 (0.288)\t\nEpoch: [0][280/395]\tTime 0.286 (0.288)\t\nEpoch: [0][290/395]\tTime 0.290 (0.288)\t\nEpoch: [0][300/395]\tTime 0.297 (0.288)\t\nEpoch: [0][310/395]\tTime 0.283 (0.288)\t\nEpoch: [0][320/395]\tTime 0.284 (0.288)\t\nEpoch: [0][330/395]\tTime 0.282 (0.288)\t\nEpoch: [0][340/395]\tTime 0.297 (0.288)\t\nEpoch: [0][350/395]\tTime 0.289 (0.288)\t\nEpoch: [0][360/395]\tTime 0.292 (0.288)\t\nEpoch: [0][370/395]\tTime 0.284 (0.288)\t\nEpoch: [0][380/395]\tTime 0.292 (0.288)\t\nEpoch: [0][390/395]\tTime 0.290 (0.288)\t\nAccuracy of Class 0: 0.0720\nAccuracy of Class 1: 0.5560\nAccuracy of Class 2: 0.4520\nAccuracy of Class 3: 0.8200\nAccuracy of Class 4: 0.2560\nAccuracy of Class 5: 0.3520\nAccuracy of Class 6: 0.8080\nAccuracy of Class 7: 0.4480\nAccuracy of Class 8: 0.2920\nAccuracy of Class 9: 0.0000\nAccuracy of Class 10: 0.3360\nAccuracy of Class 11: 0.7160\nAccuracy of Class 12: 0.2480\nAccuracy of Class 13: 0.1040\nAccuracy of Class 14: 0.4080\nAccuracy of Class 15: 0.0840\nAccuracy of Class 16: 0.2840\nAccuracy of Class 17: 0.3480\nAccuracy of Class 18: 0.0920\nAccuracy of Class 19: 0.4720\nAccuracy of Class 20: 0.6200\nAccuracy of Class 21: 0.3800\nAccuracy of Class 22: 0.2240\nAccuracy of Class 23: 0.4880\nAccuracy of Class 24: 0.8600\nAccuracy of Class 25: 0.2360\nAccuracy of Class 26: 0.5160\nAccuracy of Class 27: 0.3160\nAccuracy of Class 28: 0.3320\nAccuracy of Class 29: 0.3320\nAccuracy of Class 30: 0.4240\nAccuracy of Class 31: 0.5400\nAccuracy of Class 32: 0.7160\nAccuracy of Class 33: 0.9560\nAccuracy of Class 34: 0.5440\nAccuracy of Class 35: 0.5000\nAccuracy of Class 36: 0.2480\nAccuracy of Class 37: 0.1840\nAccuracy of Class 38: 0.3720\nAccuracy of Class 39: 0.2680\nAccuracy of Class 40: 0.5680\nAccuracy of Class 41: 0.2400\nAccuracy of Class 42: 0.1320\nAccuracy of Class 43: 0.3720\nAccuracy of Class 44: 0.7080\nAccuracy of Class 45: 0.6280\nAccuracy of Class 46: 0.5120\nAccuracy of Class 47: 0.1400\nAccuracy of Class 48: 0.2440\nAccuracy of Class 49: 0.0880\nAccuracy of Class 50: 0.5080\nAccuracy of Class 51: 0.7360\nAccuracy of Class 52: 0.0400\nAccuracy of Class 53: 0.2320\nAccuracy of Class 54: 0.4560\nAccuracy of Class 55: 0.2680\nAccuracy of Class 56: 0.0760\nAccuracy of Class 57: 0.0400\nAccuracy of Class 58: 0.0200\nAccuracy of Class 59: 0.3520\nAccuracy of Class 60: 0.2240\nAccuracy of Class 61: 0.1560\nAccuracy of Class 62: 0.3000\nAccuracy of Class 63: 0.8080\nAccuracy of Class 64: 0.6720\nAccuracy of Class 65: 0.7200\nAccuracy of Class 66: 0.3000\nAccuracy of Class 67: 0.0520\nAccuracy of Class 68: 0.6560\nAccuracy of Class 69: 0.7080\nAccuracy of Class 70: 0.8840\nAccuracy of Class 71: 0.5000\nAccuracy of Class 72: 0.3640\nAccuracy of Class 73: 0.4120\nAccuracy of Class 74: 0.4720\nAccuracy of Class 75: 0.6480\nAccuracy of Class 76: 0.6280\nAccuracy of Class 77: 0.0760\nAccuracy of Class 78: 0.6240\nAccuracy of Class 79: 0.3800\nAccuracy of Class 80: 0.4840\nAccuracy of Class 81: 0.5880\nAccuracy of Class 82: 0.0120\nAccuracy of Class 83: 0.6240\nAccuracy of Class 84: 0.6760\nAccuracy of Class 85: 0.4400\nAccuracy of Class 86: 0.6560\nAccuracy of Class 87: 0.0840\nAccuracy of Class 88: 0.7760\nAccuracy of Class 89: 0.4280\nAccuracy of Class 90: 0.1800\nAccuracy of Class 91: 0.1200\nAccuracy of Class 92: 0.3320\nAccuracy of Class 93: 0.2200\nAccuracy of Class 94: 0.4960\nAccuracy of Class 95: 0.1800\nAccuracy of Class 96: 0.0840\nAccuracy of Class 97: 0.1480\nAccuracy of Class 98: 0.4640\nAccuracy of Class 99: 0.4280\nAccuracy of Class 100: 0.3480\n* Prec @1: 0.3952\nEpoch: [1][0/1184]\tTime 0.015 (0.015)\tLoss 2.5213 (2.5213)\tPrec @1 0.4062 (0.4062)\t\nEpoch: [1][10/1184]\tTime 0.907 (0.745)\tLoss 2.3413 (2.4400)\tPrec @1 0.4062 (0.4062)\t\nEpoch: [1][20/1184]\tTime 0.912 (0.780)\tLoss 2.3561 (2.3264)\tPrec @1 0.4375 (0.4196)\t\nEpoch: [1][30/1184]\tTime 0.907 (0.792)\tLoss 2.0304 (2.2618)\tPrec @1 0.4688 (0.4304)\t\nEpoch: [1][40/1184]\tTime 0.908 (0.799)\tLoss 2.0257 (2.1851)\tPrec @1 0.4844 (0.4501)\t\nEpoch: [1][50/1184]\tTime 0.908 (0.803)\tLoss 1.9473 (2.1425)\tPrec @1 0.5000 (0.4614)\t\nEpoch: [1][60/1184]\tTime 0.909 (0.806)\tLoss 1.8030 (2.1464)\tPrec @1 0.5781 (0.4593)\t\nEpoch: [1][70/1184]\tTime 0.913 (0.808)\tLoss 2.0739 (2.1246)\tPrec @1 0.4531 (0.4635)\t\nEpoch: [1][80/1184]\tTime 0.910 (0.809)\tLoss 1.9824 (2.1174)\tPrec @1 0.4219 (0.4655)\t\nEpoch: [1][90/1184]\tTime 0.907 (0.811)\tLoss 1.3990 (2.0835)\tPrec @1 0.6406 (0.4732)\t\nEpoch: [1][100/1184]\tTime 0.910 (0.812)\tLoss 1.9238 (2.0728)\tPrec @1 0.4688 (0.4762)\t\nEpoch: [1][110/1184]\tTime 0.922 (0.813)\tLoss 1.8502 (2.0513)\tPrec @1 0.4844 (0.4793)\t\nEpoch: [1][120/1184]\tTime 0.918 (0.814)\tLoss 1.9751 (2.0283)\tPrec @1 0.5312 (0.4854)\t\nEpoch: [1][130/1184]\tTime 0.911 (0.814)\tLoss 1.8265 (2.0136)\tPrec @1 0.5312 (0.4887)\t\nEpoch: [1][140/1184]\tTime 0.914 (0.815)\tLoss 1.8184 (2.0065)\tPrec @1 0.5469 (0.4893)\t\nEpoch: [1][150/1184]\tTime 0.909 (0.816)\tLoss 1.8077 (1.9942)\tPrec @1 0.4531 (0.4912)\t\nEpoch: [1][160/1184]\tTime 0.909 (0.816)\tLoss 1.5436 (1.9809)\tPrec @1 0.5469 (0.4942)\t\nEpoch: [1][170/1184]\tTime 0.914 (0.816)\tLoss 1.5045 (1.9737)\tPrec @1 0.5938 (0.4961)\t\nEpoch: [1][180/1184]\tTime 0.908 (0.816)\tLoss 1.4300 (1.9631)\tPrec @1 0.6562 (0.4999)\t\nEpoch: [1][190/1184]\tTime 0.910 (0.816)\tLoss 2.0601 (1.9525)\tPrec @1 0.4844 (0.5021)\t\nEpoch: [1][200/1184]\tTime 0.908 (0.817)\tLoss 2.1002 (1.9424)\tPrec @1 0.4219 (0.5038)\t\nEpoch: [1][210/1184]\tTime 0.909 (0.817)\tLoss 1.8675 (1.9333)\tPrec @1 0.4844 (0.5051)\t\nEpoch: [1][220/1184]\tTime 0.910 (0.817)\tLoss 1.5445 (1.9297)\tPrec @1 0.5469 (0.5066)\t\nEpoch: [1][230/1184]\tTime 0.910 (0.817)\tLoss 1.5569 (1.9245)\tPrec @1 0.5781 (0.5077)\t\nEpoch: [1][240/1184]\tTime 0.910 (0.817)\tLoss 2.0216 (1.9176)\tPrec @1 0.5156 (0.5091)\t\nEpoch: [1][250/1184]\tTime 0.925 (0.818)\tLoss 1.7635 (1.9187)\tPrec @1 0.5781 (0.5090)\t\nEpoch: [1][260/1184]\tTime 0.914 (0.818)\tLoss 1.6889 (1.9155)\tPrec @1 0.6562 (0.5100)\t\nEpoch: [1][270/1184]\tTime 0.911 (0.818)\tLoss 1.5971 (1.9101)\tPrec @1 0.5469 (0.5107)\t\nEpoch: [1][280/1184]\tTime 0.909 (0.818)\tLoss 1.8744 (1.9053)\tPrec @1 0.6094 (0.5123)\t\nEpoch: [1][290/1184]\tTime 0.910 (0.818)\tLoss 1.8570 (1.9054)\tPrec @1 0.5781 (0.5125)\t\nEpoch: [1][300/1184]\tTime 0.909 (0.818)\tLoss 1.3215 (1.8984)\tPrec @1 0.6250 (0.5145)\t\nEpoch: [1][310/1184]\tTime 0.909 (0.818)\tLoss 1.6864 (1.8901)\tPrec @1 0.5938 (0.5165)\t\nEpoch: [1][320/1184]\tTime 0.911 (0.818)\tLoss 1.4958 (1.8869)\tPrec @1 0.5625 (0.5165)\t\nEpoch: [1][330/1184]\tTime 0.909 (0.819)\tLoss 1.8873 (1.8836)\tPrec @1 0.5312 (0.5175)\t\nEpoch: [1][340/1184]\tTime 0.923 (0.819)\tLoss 1.3971 (1.8781)\tPrec @1 0.5781 (0.5178)\t\nEpoch: [1][350/1184]\tTime 0.921 (0.819)\tLoss 1.8032 (1.8727)\tPrec @1 0.5000 (0.5191)\t\nEpoch: [1][360/1184]\tTime 0.916 (0.819)\tLoss 1.5955 (1.8698)\tPrec @1 0.6250 (0.5193)\t\nEpoch: [1][370/1184]\tTime 0.917 (0.819)\tLoss 1.7496 (1.8676)\tPrec @1 0.4844 (0.5200)\t\nEpoch: [1][380/1184]\tTime 0.912 (0.819)\tLoss 1.7021 (1.8644)\tPrec @1 0.6094 (0.5216)\t\nEpoch: [1][390/1184]\tTime 0.911 (0.819)\tLoss 2.0567 (1.8607)\tPrec @1 0.4531 (0.5221)\t\nEpoch: [1][400/1184]\tTime 0.909 (0.819)\tLoss 1.7499 (1.8576)\tPrec @1 0.4844 (0.5223)\t\nEpoch: [1][410/1184]\tTime 0.906 (0.819)\tLoss 1.7237 (1.8531)\tPrec @1 0.5000 (0.5234)\t\nEpoch: [1][420/1184]\tTime 0.908 (0.819)\tLoss 2.1737 (1.8516)\tPrec @1 0.4688 (0.5238)\t\nEpoch: [1][430/1184]\tTime 0.914 (0.819)\tLoss 1.8238 (1.8488)\tPrec @1 0.5312 (0.5241)\t\nEpoch: [1][440/1184]\tTime 0.919 (0.820)\tLoss 1.1801 (1.8444)\tPrec @1 0.6875 (0.5250)\t\nEpoch: [1][450/1184]\tTime 0.911 (0.820)\tLoss 1.5821 (1.8405)\tPrec @1 0.6406 (0.5257)\t\nEpoch: [1][460/1184]\tTime 0.913 (0.820)\tLoss 1.6447 (1.8383)\tPrec @1 0.5938 (0.5265)\t\nEpoch: [1][470/1184]\tTime 0.911 (0.820)\tLoss 1.8119 (1.8363)\tPrec @1 0.5781 (0.5267)\t\nEpoch: [1][480/1184]\tTime 0.921 (0.820)\tLoss 2.0781 (1.8325)\tPrec @1 0.4688 (0.5280)\t\nEpoch: [1][490/1184]\tTime 0.917 (0.820)\tLoss 2.0571 (1.8291)\tPrec @1 0.4844 (0.5286)\t\nEpoch: [1][500/1184]\tTime 0.908 (0.820)\tLoss 1.7653 (1.8250)\tPrec @1 0.5312 (0.5295)\t\nEpoch: [1][510/1184]\tTime 0.910 (0.820)\tLoss 1.6188 (1.8226)\tPrec @1 0.5781 (0.5298)\t\nEpoch: [1][520/1184]\tTime 0.907 (0.820)\tLoss 1.8757 (1.8195)\tPrec @1 0.4531 (0.5302)\t\nEpoch: [1][530/1184]\tTime 0.909 (0.820)\tLoss 1.7149 (1.8168)\tPrec @1 0.5156 (0.5308)\t\nEpoch: [1][540/1184]\tTime 0.911 (0.820)\tLoss 1.4898 (1.8145)\tPrec @1 0.5781 (0.5314)\t\nEpoch: [1][550/1184]\tTime 0.914 (0.820)\tLoss 1.7260 (1.8126)\tPrec @1 0.5781 (0.5316)\t\nEpoch: [1][560/1184]\tTime 0.917 (0.820)\tLoss 1.7238 (1.8093)\tPrec @1 0.5312 (0.5322)\t\nEpoch: [1][570/1184]\tTime 0.923 (0.820)\tLoss 2.0593 (1.8082)\tPrec @1 0.5312 (0.5324)\t\nEpoch: [1][580/1184]\tTime 0.908 (0.820)\tLoss 1.8525 (1.8048)\tPrec @1 0.5625 (0.5333)\t\nEpoch: [1][590/1184]\tTime 0.910 (0.820)\tLoss 1.1598 (1.8017)\tPrec @1 0.6719 (0.5339)\t\nEpoch: [1][600/1184]\tTime 0.907 (0.820)\tLoss 1.7264 (1.8000)\tPrec @1 0.5625 (0.5339)\t\nEpoch: [1][610/1184]\tTime 0.911 (0.820)\tLoss 1.5233 (1.7983)\tPrec @1 0.5938 (0.5343)\t\nEpoch: [1][620/1184]\tTime 0.915 (0.821)\tLoss 1.4830 (1.7979)\tPrec @1 0.6406 (0.5346)\t\nEpoch: [1][630/1184]\tTime 0.909 (0.821)\tLoss 1.2382 (1.7961)\tPrec @1 0.6875 (0.5352)\t\nEpoch: [1][640/1184]\tTime 0.910 (0.821)\tLoss 1.8030 (1.7928)\tPrec @1 0.5938 (0.5356)\t\nEpoch: [1][650/1184]\tTime 0.920 (0.821)\tLoss 1.6010 (1.7914)\tPrec @1 0.6250 (0.5360)\t\nEpoch: [1][660/1184]\tTime 0.909 (0.821)\tLoss 1.8613 (1.7907)\tPrec @1 0.4531 (0.5360)\t\nEpoch: [1][670/1184]\tTime 0.911 (0.821)\tLoss 1.7034 (1.7884)\tPrec @1 0.5000 (0.5367)\t\nEpoch: [1][680/1184]\tTime 0.910 (0.821)\tLoss 2.3017 (1.7883)\tPrec @1 0.4688 (0.5368)\t\nEpoch: [1][690/1184]\tTime 0.922 (0.821)\tLoss 1.5317 (1.7882)\tPrec @1 0.5938 (0.5369)\t\nEpoch: [1][700/1184]\tTime 0.913 (0.821)\tLoss 1.7776 (1.7867)\tPrec @1 0.5156 (0.5374)\t\nEpoch: [1][710/1184]\tTime 0.914 (0.821)\tLoss 1.4018 (1.7851)\tPrec @1 0.5938 (0.5375)\t\nEpoch: [1][720/1184]\tTime 0.923 (0.821)\tLoss 1.8305 (1.7841)\tPrec @1 0.6094 (0.5378)\t\nEpoch: [1][730/1184]\tTime 0.908 (0.821)\tLoss 1.5609 (1.7819)\tPrec @1 0.5781 (0.5383)\t\nEpoch: [1][740/1184]\tTime 0.917 (0.821)\tLoss 1.5445 (1.7803)\tPrec @1 0.5938 (0.5387)\t\nEpoch: [1][750/1184]\tTime 0.912 (0.821)\tLoss 2.2753 (1.7784)\tPrec @1 0.4375 (0.5390)\t\nEpoch: [1][760/1184]\tTime 0.916 (0.821)\tLoss 1.5421 (1.7783)\tPrec @1 0.5938 (0.5391)\t\nEpoch: [1][770/1184]\tTime 0.912 (0.821)\tLoss 1.3527 (1.7760)\tPrec @1 0.5938 (0.5396)\t\nEpoch: [1][780/1184]\tTime 0.908 (0.821)\tLoss 1.9730 (1.7742)\tPrec @1 0.5625 (0.5403)\t\nEpoch: [1][790/1184]\tTime 0.921 (0.821)\tLoss 1.7789 (1.7731)\tPrec @1 0.5312 (0.5403)\t\nEpoch: [1][800/1184]\tTime 0.920 (0.821)\tLoss 2.0048 (1.7727)\tPrec @1 0.4688 (0.5404)\t\nEpoch: [1][810/1184]\tTime 0.912 (0.821)\tLoss 1.4812 (1.7708)\tPrec @1 0.5781 (0.5407)\t\nEpoch: [1][820/1184]\tTime 0.912 (0.821)\tLoss 2.0195 (1.7681)\tPrec @1 0.5000 (0.5413)\t\nEpoch: [1][830/1184]\tTime 0.915 (0.821)\tLoss 1.7656 (1.7664)\tPrec @1 0.5312 (0.5419)\t\nEpoch: [1][840/1184]\tTime 0.924 (0.821)\tLoss 2.0852 (1.7661)\tPrec @1 0.5156 (0.5422)\t\nEpoch: [1][850/1184]\tTime 0.922 (0.821)\tLoss 1.9743 (1.7637)\tPrec @1 0.5312 (0.5426)\t\nEpoch: [1][860/1184]\tTime 0.924 (0.821)\tLoss 1.5706 (1.7622)\tPrec @1 0.6250 (0.5431)\t\nEpoch: [1][870/1184]\tTime 0.923 (0.821)\tLoss 1.4851 (1.7612)\tPrec @1 0.5938 (0.5433)\t\nEpoch: [1][880/1184]\tTime 0.923 (0.822)\tLoss 1.7593 (1.7601)\tPrec @1 0.4688 (0.5435)\t\nEpoch: [1][890/1184]\tTime 0.917 (0.822)\tLoss 1.9064 (1.7587)\tPrec @1 0.5000 (0.5437)\t\nEpoch: [1][900/1184]\tTime 0.918 (0.822)\tLoss 1.2853 (1.7581)\tPrec @1 0.6562 (0.5439)\t\nEpoch: [1][910/1184]\tTime 0.922 (0.822)\tLoss 1.5250 (1.7571)\tPrec @1 0.6250 (0.5442)\t\nEpoch: [1][920/1184]\tTime 0.924 (0.822)\tLoss 1.7962 (1.7558)\tPrec @1 0.5312 (0.5444)\t\nEpoch: [1][930/1184]\tTime 0.920 (0.822)\tLoss 1.8745 (1.7544)\tPrec @1 0.5469 (0.5448)\t\nEpoch: [1][940/1184]\tTime 0.923 (0.822)\tLoss 1.4414 (1.7530)\tPrec @1 0.5625 (0.5449)\t\nEpoch: [1][950/1184]\tTime 0.912 (0.822)\tLoss 2.1091 (1.7519)\tPrec @1 0.5312 (0.5450)\t\nEpoch: [1][960/1184]\tTime 0.916 (0.822)\tLoss 1.5253 (1.7496)\tPrec @1 0.5938 (0.5458)\t\nEpoch: [1][970/1184]\tTime 0.918 (0.822)\tLoss 1.5355 (1.7484)\tPrec @1 0.6094 (0.5460)\t\nEpoch: [1][980/1184]\tTime 0.923 (0.822)\tLoss 2.0247 (1.7474)\tPrec @1 0.5469 (0.5462)\t\nEpoch: [1][990/1184]\tTime 0.913 (0.822)\tLoss 1.6067 (1.7451)\tPrec @1 0.6719 (0.5469)\t\nEpoch: [1][1000/1184]\tTime 0.915 (0.822)\tLoss 1.5237 (1.7446)\tPrec @1 0.5625 (0.5469)\t\nEpoch: [1][1010/1184]\tTime 0.916 (0.822)\tLoss 1.3670 (1.7425)\tPrec @1 0.5469 (0.5473)\t\nEpoch: [1][1020/1184]\tTime 0.912 (0.822)\tLoss 1.5954 (1.7414)\tPrec @1 0.6562 (0.5475)\t\nEpoch: [1][1030/1184]\tTime 0.911 (0.822)\tLoss 1.4149 (1.7386)\tPrec @1 0.6094 (0.5479)\t\nEpoch: [1][1040/1184]\tTime 0.926 (0.822)\tLoss 1.7751 (1.7374)\tPrec @1 0.5625 (0.5484)\t\nEpoch: [1][1050/1184]\tTime 0.924 (0.822)\tLoss 1.6632 (1.7366)\tPrec @1 0.5625 (0.5484)\t\nEpoch: [1][1060/1184]\tTime 0.926 (0.823)\tLoss 1.5651 (1.7353)\tPrec @1 0.5781 (0.5486)\t\nEpoch: [1][1070/1184]\tTime 0.914 (0.823)\tLoss 1.6113 (1.7339)\tPrec @1 0.5781 (0.5489)\t\nEpoch: [1][1080/1184]\tTime 0.911 (0.823)\tLoss 1.9596 (1.7332)\tPrec @1 0.5156 (0.5492)\t\nEpoch: [1][1090/1184]\tTime 0.923 (0.823)\tLoss 1.6157 (1.7330)\tPrec @1 0.5781 (0.5492)\t\nEpoch: [1][1100/1184]\tTime 0.922 (0.823)\tLoss 1.6262 (1.7311)\tPrec @1 0.6250 (0.5498)\t\nEpoch: [1][1110/1184]\tTime 0.914 (0.823)\tLoss 1.3307 (1.7288)\tPrec @1 0.6094 (0.5503)\t\nEpoch: [1][1120/1184]\tTime 0.912 (0.823)\tLoss 1.5976 (1.7282)\tPrec @1 0.5781 (0.5503)\t\nEpoch: [1][1130/1184]\tTime 0.915 (0.823)\tLoss 1.7700 (1.7267)\tPrec @1 0.5156 (0.5508)\t\nEpoch: [1][1140/1184]\tTime 0.917 (0.823)\tLoss 1.7983 (1.7263)\tPrec @1 0.5312 (0.5510)\t\nEpoch: [1][1150/1184]\tTime 0.924 (0.823)\tLoss 1.8820 (1.7248)\tPrec @1 0.5156 (0.5514)\t\nEpoch: [1][1160/1184]\tTime 0.926 (0.823)\tLoss 1.4775 (1.7231)\tPrec @1 0.6406 (0.5518)\t\nEpoch: [1][1170/1184]\tTime 0.922 (0.823)\tLoss 1.4236 (1.7225)\tPrec @1 0.6250 (0.5520)\t\nEpoch: [1][1180/1184]\tTime 0.912 (0.823)\tLoss 1.5287 (1.7202)\tPrec @1 0.5625 (0.5526)\t\n\n*** WARNING: skipped 85241 bytes of output ***\n\nEpoch: [7][800/1184]\tTime 0.925 (0.827)\tLoss 1.4588 (1.4023)\tPrec @1 0.6250 (0.6276)\t\nEpoch: [7][810/1184]\tTime 0.925 (0.827)\tLoss 1.3086 (1.4015)\tPrec @1 0.5625 (0.6277)\t\nEpoch: [7][820/1184]\tTime 0.921 (0.827)\tLoss 1.1783 (1.3997)\tPrec @1 0.6875 (0.6279)\t\nEpoch: [7][830/1184]\tTime 0.926 (0.827)\tLoss 1.3781 (1.3991)\tPrec @1 0.6406 (0.6280)\t\nEpoch: [7][840/1184]\tTime 0.928 (0.827)\tLoss 1.3308 (1.3986)\tPrec @1 0.6875 (0.6284)\t\nEpoch: [7][850/1184]\tTime 0.927 (0.827)\tLoss 1.5640 (1.3979)\tPrec @1 0.7031 (0.6289)\t\nEpoch: [7][860/1184]\tTime 0.918 (0.827)\tLoss 0.7992 (1.3967)\tPrec @1 0.7969 (0.6293)\t\nEpoch: [7][870/1184]\tTime 0.919 (0.827)\tLoss 1.9279 (1.3979)\tPrec @1 0.4531 (0.6289)\t\nEpoch: [7][880/1184]\tTime 0.927 (0.827)\tLoss 1.4714 (1.3967)\tPrec @1 0.5938 (0.6289)\t\nEpoch: [7][890/1184]\tTime 0.925 (0.827)\tLoss 1.1074 (1.3968)\tPrec @1 0.6875 (0.6288)\t\nEpoch: [7][900/1184]\tTime 0.923 (0.828)\tLoss 1.2036 (1.3970)\tPrec @1 0.6406 (0.6284)\t\nEpoch: [7][910/1184]\tTime 0.928 (0.828)\tLoss 1.1780 (1.3968)\tPrec @1 0.6875 (0.6285)\t\nEpoch: [7][920/1184]\tTime 0.928 (0.828)\tLoss 1.1643 (1.3980)\tPrec @1 0.6719 (0.6282)\t\nEpoch: [7][930/1184]\tTime 0.916 (0.828)\tLoss 0.8978 (1.3973)\tPrec @1 0.7344 (0.6283)\t\nEpoch: [7][940/1184]\tTime 0.921 (0.828)\tLoss 1.4307 (1.3981)\tPrec @1 0.6250 (0.6281)\t\nEpoch: [7][950/1184]\tTime 0.925 (0.828)\tLoss 1.5222 (1.3992)\tPrec @1 0.6094 (0.6277)\t\nEpoch: [7][960/1184]\tTime 0.924 (0.828)\tLoss 1.9139 (1.3996)\tPrec @1 0.4688 (0.6277)\t\nEpoch: [7][970/1184]\tTime 0.916 (0.828)\tLoss 1.2985 (1.3998)\tPrec @1 0.6406 (0.6276)\t\nEpoch: [7][980/1184]\tTime 0.925 (0.828)\tLoss 1.5436 (1.4001)\tPrec @1 0.5469 (0.6276)\t\nEpoch: [7][990/1184]\tTime 0.929 (0.828)\tLoss 1.5700 (1.3997)\tPrec @1 0.6250 (0.6277)\t\nEpoch: [7][1000/1184]\tTime 0.924 (0.828)\tLoss 1.1448 (1.3992)\tPrec @1 0.7500 (0.6279)\t\nEpoch: [7][1010/1184]\tTime 0.927 (0.828)\tLoss 1.4056 (1.4004)\tPrec @1 0.6406 (0.6274)\t\nEpoch: [7][1020/1184]\tTime 0.924 (0.828)\tLoss 1.4327 (1.4004)\tPrec @1 0.6562 (0.6274)\t\nEpoch: [7][1030/1184]\tTime 0.917 (0.828)\tLoss 1.6481 (1.3996)\tPrec @1 0.5625 (0.6275)\t\nEpoch: [7][1040/1184]\tTime 0.927 (0.828)\tLoss 1.5136 (1.3993)\tPrec @1 0.5938 (0.6276)\t\nEpoch: [7][1050/1184]\tTime 0.918 (0.828)\tLoss 1.0485 (1.3982)\tPrec @1 0.6875 (0.6279)\t\nEpoch: [7][1060/1184]\tTime 0.924 (0.828)\tLoss 1.3607 (1.3977)\tPrec @1 0.6719 (0.6280)\t\nEpoch: [7][1070/1184]\tTime 0.926 (0.828)\tLoss 1.3291 (1.3972)\tPrec @1 0.6719 (0.6283)\t\nEpoch: [7][1080/1184]\tTime 0.918 (0.828)\tLoss 1.4832 (1.3973)\tPrec @1 0.5938 (0.6284)\t\nEpoch: [7][1090/1184]\tTime 0.915 (0.828)\tLoss 1.4078 (1.3969)\tPrec @1 0.6875 (0.6282)\t\nEpoch: [7][1100/1184]\tTime 0.925 (0.828)\tLoss 1.4276 (1.3976)\tPrec @1 0.6562 (0.6281)\t\nEpoch: [7][1110/1184]\tTime 0.924 (0.828)\tLoss 1.1024 (1.3968)\tPrec @1 0.6562 (0.6284)\t\nEpoch: [7][1120/1184]\tTime 0.925 (0.828)\tLoss 1.4250 (1.3966)\tPrec @1 0.6719 (0.6284)\t\nEpoch: [7][1130/1184]\tTime 0.919 (0.828)\tLoss 1.1090 (1.3966)\tPrec @1 0.6875 (0.6284)\t\nEpoch: [7][1140/1184]\tTime 0.923 (0.828)\tLoss 1.4172 (1.3966)\tPrec @1 0.6562 (0.6286)\t\nEpoch: [7][1150/1184]\tTime 0.923 (0.828)\tLoss 1.4111 (1.3962)\tPrec @1 0.5781 (0.6286)\t\nEpoch: [7][1160/1184]\tTime 0.915 (0.828)\tLoss 1.5937 (1.3980)\tPrec @1 0.5625 (0.6282)\t\nEpoch: [7][1170/1184]\tTime 0.921 (0.828)\tLoss 1.3468 (1.3977)\tPrec @1 0.6562 (0.6282)\t\nEpoch: [7][1180/1184]\tTime 0.914 (0.828)\tLoss 1.2190 (1.3976)\tPrec @1 0.6719 (0.6281)\t\nEpoch: [7][0/395]\tTime 0.284 (0.284)\t\nEpoch: [7][10/395]\tTime 0.296 (0.291)\t\nEpoch: [7][20/395]\tTime 0.285 (0.291)\t\nEpoch: [7][30/395]\tTime 0.287 (0.290)\t\nEpoch: [7][40/395]\tTime 0.285 (0.290)\t\nEpoch: [7][50/395]\tTime 0.286 (0.290)\t\nEpoch: [7][60/395]\tTime 0.286 (0.289)\t\nEpoch: [7][70/395]\tTime 0.292 (0.289)\t\nEpoch: [7][80/395]\tTime 0.282 (0.288)\t\nEpoch: [7][90/395]\tTime 0.286 (0.289)\t\nEpoch: [7][100/395]\tTime 0.283 (0.288)\t\nEpoch: [7][110/395]\tTime 0.289 (0.288)\t\nEpoch: [7][120/395]\tTime 0.293 (0.288)\t\nEpoch: [7][130/395]\tTime 0.288 (0.288)\t\nEpoch: [7][140/395]\tTime 0.293 (0.289)\t\nEpoch: [7][150/395]\tTime 0.285 (0.288)\t\nEpoch: [7][160/395]\tTime 0.292 (0.288)\t\nEpoch: [7][170/395]\tTime 0.287 (0.288)\t\nEpoch: [7][180/395]\tTime 0.294 (0.288)\t\nEpoch: [7][190/395]\tTime 0.285 (0.288)\t\nEpoch: [7][200/395]\tTime 0.280 (0.288)\t\nEpoch: [7][210/395]\tTime 0.284 (0.288)\t\nEpoch: [7][220/395]\tTime 0.284 (0.288)\t\nEpoch: [7][230/395]\tTime 0.293 (0.288)\t\nEpoch: [7][240/395]\tTime 0.284 (0.288)\t\nEpoch: [7][250/395]\tTime 0.293 (0.288)\t\nEpoch: [7][260/395]\tTime 0.282 (0.288)\t\nEpoch: [7][270/395]\tTime 0.293 (0.288)\t\nEpoch: [7][280/395]\tTime 0.282 (0.288)\t\nEpoch: [7][290/395]\tTime 0.291 (0.288)\t\nEpoch: [7][300/395]\tTime 0.282 (0.288)\t\nEpoch: [7][310/395]\tTime 0.293 (0.288)\t\nEpoch: [7][320/395]\tTime 0.288 (0.288)\t\nEpoch: [7][330/395]\tTime 0.297 (0.288)\t\nEpoch: [7][340/395]\tTime 0.290 (0.288)\t\nEpoch: [7][350/395]\tTime 0.279 (0.288)\t\nEpoch: [7][360/395]\tTime 0.285 (0.288)\t\nEpoch: [7][370/395]\tTime 0.286 (0.288)\t\nEpoch: [7][380/395]\tTime 0.284 (0.288)\t\nEpoch: [7][390/395]\tTime 0.283 (0.288)\t\nAccuracy of Class 0: 0.2400\nAccuracy of Class 1: 0.6000\nAccuracy of Class 2: 0.7240\nAccuracy of Class 3: 0.7720\nAccuracy of Class 4: 0.6760\nAccuracy of Class 5: 0.5280\nAccuracy of Class 6: 0.8240\nAccuracy of Class 7: 0.8040\nAccuracy of Class 8: 0.4240\nAccuracy of Class 9: 0.3080\nAccuracy of Class 10: 0.5880\nAccuracy of Class 11: 0.7880\nAccuracy of Class 12: 0.6080\nAccuracy of Class 13: 0.6760\nAccuracy of Class 14: 0.7080\nAccuracy of Class 15: 0.4080\nAccuracy of Class 16: 0.6960\nAccuracy of Class 17: 0.4760\nAccuracy of Class 18: 0.3400\nAccuracy of Class 19: 0.6240\nAccuracy of Class 20: 0.7280\nAccuracy of Class 21: 0.6680\nAccuracy of Class 22: 0.3080\nAccuracy of Class 23: 0.7640\nAccuracy of Class 24: 0.7880\nAccuracy of Class 25: 0.7640\nAccuracy of Class 26: 0.5400\nAccuracy of Class 27: 0.7360\nAccuracy of Class 28: 0.7640\nAccuracy of Class 29: 0.7600\nAccuracy of Class 30: 0.8560\nAccuracy of Class 31: 0.6760\nAccuracy of Class 32: 0.8560\nAccuracy of Class 33: 0.9880\nAccuracy of Class 34: 0.7640\nAccuracy of Class 35: 0.7520\nAccuracy of Class 36: 0.5400\nAccuracy of Class 37: 0.4640\nAccuracy of Class 38: 0.7680\nAccuracy of Class 39: 0.3520\nAccuracy of Class 40: 0.8720\nAccuracy of Class 41: 0.7040\nAccuracy of Class 42: 0.5680\nAccuracy of Class 43: 0.7400\nAccuracy of Class 44: 0.7200\nAccuracy of Class 45: 0.7800\nAccuracy of Class 46: 0.5760\nAccuracy of Class 47: 0.3960\nAccuracy of Class 48: 0.6600\nAccuracy of Class 49: 0.4920\nAccuracy of Class 50: 0.3640\nAccuracy of Class 51: 0.8680\nAccuracy of Class 52: 0.6600\nAccuracy of Class 53: 0.6280\nAccuracy of Class 54: 0.8720\nAccuracy of Class 55: 0.6480\nAccuracy of Class 56: 0.2840\nAccuracy of Class 57: 0.4240\nAccuracy of Class 58: 0.4800\nAccuracy of Class 59: 0.4760\nAccuracy of Class 60: 0.7880\nAccuracy of Class 61: 0.6400\nAccuracy of Class 62: 0.5840\nAccuracy of Class 63: 0.9080\nAccuracy of Class 64: 0.8200\nAccuracy of Class 65: 0.8160\nAccuracy of Class 66: 0.4120\nAccuracy of Class 67: 0.2520\nAccuracy of Class 68: 0.8320\nAccuracy of Class 69: 0.8600\nAccuracy of Class 70: 0.8160\nAccuracy of Class 71: 0.6760\nAccuracy of Class 72: 0.7160\nAccuracy of Class 73: 0.5400\nAccuracy of Class 74: 0.5800\nAccuracy of Class 75: 0.8440\nAccuracy of Class 76: 0.8000\nAccuracy of Class 77: 0.4040\nAccuracy of Class 78: 0.7360\nAccuracy of Class 79: 0.7520\nAccuracy of Class 80: 0.6520\nAccuracy of Class 81: 0.6280\nAccuracy of Class 82: 0.3200\nAccuracy of Class 83: 0.8240\nAccuracy of Class 84: 0.5480\nAccuracy of Class 85: 0.5400\nAccuracy of Class 86: 0.7880\nAccuracy of Class 87: 0.5200\nAccuracy of Class 88: 0.8800\nAccuracy of Class 89: 0.5200\nAccuracy of Class 90: 0.7960\nAccuracy of Class 91: 0.8560\nAccuracy of Class 92: 0.6160\nAccuracy of Class 93: 0.2920\nAccuracy of Class 94: 0.6840\nAccuracy of Class 95: 0.6480\nAccuracy of Class 96: 0.3920\nAccuracy of Class 97: 0.7040\nAccuracy of Class 98: 0.5920\nAccuracy of Class 99: 0.4520\nAccuracy of Class 100: 0.7560\n* Prec @1: 0.6400\nEpoch: [8][0/1184]\tTime 0.015 (0.015)\tLoss 1.4933 (1.4933)\tPrec @1 0.5781 (0.5781)\t\nEpoch: [8][10/1184]\tTime 0.910 (0.745)\tLoss 1.6592 (1.4271)\tPrec @1 0.5938 (0.6207)\t\nEpoch: [8][20/1184]\tTime 0.919 (0.781)\tLoss 1.5517 (1.3773)\tPrec @1 0.5625 (0.6272)\t\nEpoch: [8][30/1184]\tTime 0.914 (0.795)\tLoss 1.4972 (1.4142)\tPrec @1 0.6250 (0.6220)\t\nEpoch: [8][40/1184]\tTime 0.912 (0.802)\tLoss 1.4851 (1.3965)\tPrec @1 0.6719 (0.6261)\t\nEpoch: [8][50/1184]\tTime 0.914 (0.807)\tLoss 1.7679 (1.4049)\tPrec @1 0.5781 (0.6256)\t\nEpoch: [8][60/1184]\tTime 0.910 (0.810)\tLoss 1.4717 (1.3939)\tPrec @1 0.5469 (0.6255)\t\nEpoch: [8][70/1184]\tTime 0.913 (0.812)\tLoss 1.3237 (1.3923)\tPrec @1 0.6094 (0.6276)\t\nEpoch: [8][80/1184]\tTime 0.923 (0.814)\tLoss 1.6889 (1.4004)\tPrec @1 0.5469 (0.6267)\t\nEpoch: [8][90/1184]\tTime 0.921 (0.815)\tLoss 1.9576 (1.4046)\tPrec @1 0.4531 (0.6248)\t\nEpoch: [8][100/1184]\tTime 0.922 (0.816)\tLoss 1.5020 (1.4009)\tPrec @1 0.5938 (0.6267)\t\nEpoch: [8][110/1184]\tTime 0.914 (0.817)\tLoss 1.5619 (1.3980)\tPrec @1 0.5781 (0.6263)\t\nEpoch: [8][120/1184]\tTime 0.909 (0.818)\tLoss 1.2937 (1.3896)\tPrec @1 0.6406 (0.6278)\t\nEpoch: [8][130/1184]\tTime 0.909 (0.818)\tLoss 1.1595 (1.3964)\tPrec @1 0.6719 (0.6264)\t\nEpoch: [8][140/1184]\tTime 0.911 (0.818)\tLoss 0.9821 (1.3972)\tPrec @1 0.7500 (0.6266)\t\nEpoch: [8][150/1184]\tTime 0.919 (0.818)\tLoss 1.2420 (1.3960)\tPrec @1 0.6250 (0.6272)\t\nEpoch: [8][160/1184]\tTime 0.911 (0.819)\tLoss 0.9818 (1.3908)\tPrec @1 0.6719 (0.6277)\t\nEpoch: [8][170/1184]\tTime 0.923 (0.819)\tLoss 1.3086 (1.3883)\tPrec @1 0.6562 (0.6285)\t\nEpoch: [8][180/1184]\tTime 0.911 (0.819)\tLoss 1.6762 (1.3897)\tPrec @1 0.5156 (0.6285)\t\nEpoch: [8][190/1184]\tTime 0.913 (0.820)\tLoss 1.3843 (1.3919)\tPrec @1 0.6406 (0.6283)\t\nEpoch: [8][200/1184]\tTime 0.918 (0.820)\tLoss 1.4318 (1.3853)\tPrec @1 0.5469 (0.6291)\t\nEpoch: [8][210/1184]\tTime 0.910 (0.820)\tLoss 1.5662 (1.3909)\tPrec @1 0.6094 (0.6285)\t\nEpoch: [8][220/1184]\tTime 0.919 (0.820)\tLoss 1.3013 (1.3872)\tPrec @1 0.5938 (0.6294)\t\nEpoch: [8][230/1184]\tTime 0.912 (0.821)\tLoss 1.4854 (1.3898)\tPrec @1 0.6250 (0.6291)\t\nEpoch: [8][240/1184]\tTime 0.908 (0.821)\tLoss 1.3463 (1.3932)\tPrec @1 0.6094 (0.6282)\t\nEpoch: [8][250/1184]\tTime 0.910 (0.821)\tLoss 1.0431 (1.3923)\tPrec @1 0.7344 (0.6287)\t\nEpoch: [8][260/1184]\tTime 0.923 (0.821)\tLoss 1.3914 (1.3925)\tPrec @1 0.7031 (0.6294)\t\nEpoch: [8][270/1184]\tTime 0.922 (0.821)\tLoss 1.6800 (1.3918)\tPrec @1 0.5312 (0.6293)\t\nEpoch: [8][280/1184]\tTime 0.913 (0.821)\tLoss 1.5795 (1.3909)\tPrec @1 0.5938 (0.6289)\t\nEpoch: [8][290/1184]\tTime 0.911 (0.821)\tLoss 1.4503 (1.3927)\tPrec @1 0.5781 (0.6284)\t\nEpoch: [8][300/1184]\tTime 0.910 (0.822)\tLoss 1.0160 (1.3937)\tPrec @1 0.7656 (0.6283)\t\nEpoch: [8][310/1184]\tTime 0.911 (0.822)\tLoss 1.5191 (1.3948)\tPrec @1 0.5938 (0.6280)\t\nEpoch: [8][320/1184]\tTime 0.913 (0.822)\tLoss 1.1810 (1.3915)\tPrec @1 0.6875 (0.6291)\t\nEpoch: [8][330/1184]\tTime 0.911 (0.822)\tLoss 1.2287 (1.3916)\tPrec @1 0.7031 (0.6288)\t\nEpoch: [8][340/1184]\tTime 0.916 (0.822)\tLoss 1.3266 (1.3880)\tPrec @1 0.6562 (0.6301)\t\nEpoch: [8][350/1184]\tTime 0.912 (0.822)\tLoss 1.0752 (1.3900)\tPrec @1 0.6094 (0.6298)\t\nEpoch: [8][360/1184]\tTime 0.909 (0.822)\tLoss 1.3054 (1.3897)\tPrec @1 0.6406 (0.6297)\t\nEpoch: [8][370/1184]\tTime 0.919 (0.822)\tLoss 1.6858 (1.3903)\tPrec @1 0.5156 (0.6294)\t\nEpoch: [8][380/1184]\tTime 0.914 (0.822)\tLoss 1.1612 (1.3891)\tPrec @1 0.7031 (0.6292)\t\nEpoch: [8][390/1184]\tTime 0.923 (0.822)\tLoss 0.8963 (1.3912)\tPrec @1 0.7344 (0.6288)\t\nEpoch: [8][400/1184]\tTime 0.925 (0.822)\tLoss 1.4378 (1.3912)\tPrec @1 0.5781 (0.6286)\t\nEpoch: [8][410/1184]\tTime 0.923 (0.822)\tLoss 1.3741 (1.3929)\tPrec @1 0.6094 (0.6280)\t\nEpoch: [8][420/1184]\tTime 0.921 (0.822)\tLoss 1.3541 (1.3933)\tPrec @1 0.5625 (0.6272)\t\nEpoch: [8][430/1184]\tTime 0.916 (0.822)\tLoss 1.6693 (1.3925)\tPrec @1 0.5469 (0.6276)\t\nEpoch: [8][440/1184]\tTime 0.921 (0.822)\tLoss 1.0799 (1.3955)\tPrec @1 0.6875 (0.6270)\t\nEpoch: [8][450/1184]\tTime 0.910 (0.822)\tLoss 1.2894 (1.3965)\tPrec @1 0.6250 (0.6264)\t\nEpoch: [8][460/1184]\tTime 0.922 (0.822)\tLoss 1.3501 (1.3970)\tPrec @1 0.6406 (0.6264)\t\nEpoch: [8][470/1184]\tTime 0.908 (0.822)\tLoss 1.5970 (1.3973)\tPrec @1 0.5469 (0.6263)\t\nEpoch: [8][480/1184]\tTime 0.911 (0.822)\tLoss 1.5963 (1.3982)\tPrec @1 0.5312 (0.6261)\t\nEpoch: [8][490/1184]\tTime 0.920 (0.822)\tLoss 1.2002 (1.3966)\tPrec @1 0.6562 (0.6259)\t\nEpoch: [8][500/1184]\tTime 0.909 (0.822)\tLoss 1.6898 (1.3974)\tPrec @1 0.5625 (0.6255)\t\nEpoch: [8][510/1184]\tTime 0.909 (0.822)\tLoss 1.3903 (1.3961)\tPrec @1 0.5781 (0.6258)\t\nEpoch: [8][520/1184]\tTime 0.908 (0.822)\tLoss 1.0656 (1.3952)\tPrec @1 0.6719 (0.6259)\t\nEpoch: [8][530/1184]\tTime 0.919 (0.822)\tLoss 1.3612 (1.3959)\tPrec @1 0.5938 (0.6255)\t\nEpoch: [8][540/1184]\tTime 0.912 (0.823)\tLoss 1.1521 (1.3963)\tPrec @1 0.6406 (0.6254)\t\nEpoch: [8][550/1184]\tTime 0.924 (0.823)\tLoss 1.4319 (1.3978)\tPrec @1 0.5781 (0.6250)\t\nEpoch: [8][560/1184]\tTime 0.923 (0.823)\tLoss 1.4037 (1.3979)\tPrec @1 0.6562 (0.6253)\t\nEpoch: [8][570/1184]\tTime 0.916 (0.823)\tLoss 1.9574 (1.3986)\tPrec @1 0.5312 (0.6250)\t\nEpoch: [8][580/1184]\tTime 0.915 (0.823)\tLoss 1.8138 (1.3998)\tPrec @1 0.5312 (0.6248)\t\nEpoch: [8][590/1184]\tTime 0.921 (0.823)\tLoss 1.5484 (1.3990)\tPrec @1 0.6250 (0.6250)\t\nEpoch: [8][600/1184]\tTime 0.923 (0.823)\tLoss 1.4341 (1.4014)\tPrec @1 0.6250 (0.6247)\t\nEpoch: [8][610/1184]\tTime 0.910 (0.823)\tLoss 1.2782 (1.4029)\tPrec @1 0.5938 (0.6244)\t\nEpoch: [8][620/1184]\tTime 0.909 (0.823)\tLoss 1.0234 (1.4028)\tPrec @1 0.7344 (0.6241)\t\nEpoch: [8][630/1184]\tTime 0.907 (0.823)\tLoss 1.3544 (1.4029)\tPrec @1 0.5469 (0.6240)\t\nEpoch: [8][640/1184]\tTime 0.922 (0.823)\tLoss 1.2378 (1.4012)\tPrec @1 0.6406 (0.6244)\t\nEpoch: [8][650/1184]\tTime 0.908 (0.823)\tLoss 1.1775 (1.4010)\tPrec @1 0.7031 (0.6246)\t\nEpoch: [8][660/1184]\tTime 0.909 (0.823)\tLoss 1.3259 (1.3995)\tPrec @1 0.6562 (0.6249)\t\nEpoch: [8][670/1184]\tTime 0.910 (0.823)\tLoss 1.3464 (1.3997)\tPrec @1 0.6094 (0.6249)\t\nEpoch: [8][680/1184]\tTime 0.915 (0.823)\tLoss 1.6946 (1.3998)\tPrec @1 0.5625 (0.6248)\t\nEpoch: [8][690/1184]\tTime 0.909 (0.823)\tLoss 1.0999 (1.4000)\tPrec @1 0.7188 (0.6249)\t\nEpoch: [8][700/1184]\tTime 0.908 (0.823)\tLoss 1.3363 (1.3992)\tPrec @1 0.6094 (0.6250)\t\nEpoch: [8][710/1184]\tTime 0.914 (0.823)\tLoss 1.4870 (1.3994)\tPrec @1 0.5938 (0.6250)\t\nEpoch: [8][720/1184]\tTime 0.915 (0.823)\tLoss 1.4023 (1.3984)\tPrec @1 0.6250 (0.6251)\t\nEpoch: [8][730/1184]\tTime 0.910 (0.823)\tLoss 1.6486 (1.3975)\tPrec @1 0.5469 (0.6252)\t\nEpoch: [8][740/1184]\tTime 0.913 (0.823)\tLoss 1.6509 (1.3989)\tPrec @1 0.5156 (0.6247)\t\nEpoch: [8][750/1184]\tTime 0.921 (0.823)\tLoss 1.2970 (1.3975)\tPrec @1 0.6406 (0.6250)\t\nEpoch: [8][760/1184]\tTime 0.913 (0.823)\tLoss 1.7055 (1.3968)\tPrec @1 0.5625 (0.6253)\t\nEpoch: [8][770/1184]\tTime 0.918 (0.823)\tLoss 1.0934 (1.3969)\tPrec @1 0.6875 (0.6256)\t\nEpoch: [8][780/1184]\tTime 0.921 (0.823)\tLoss 1.1929 (1.3958)\tPrec @1 0.6719 (0.6258)\t\nEpoch: [8][790/1184]\tTime 0.922 (0.823)\tLoss 1.0958 (1.3966)\tPrec @1 0.6719 (0.6259)\t\nEpoch: [8][800/1184]\tTime 0.911 (0.823)\tLoss 1.4007 (1.3979)\tPrec @1 0.7344 (0.6258)\t\nEpoch: [8][810/1184]\tTime 0.913 (0.823)\tLoss 1.2299 (1.3983)\tPrec @1 0.6562 (0.6257)\t\nEpoch: [8][820/1184]\tTime 0.921 (0.823)\tLoss 1.4845 (1.3988)\tPrec @1 0.5938 (0.6254)\t\nEpoch: [8][830/1184]\tTime 0.908 (0.823)\tLoss 1.8158 (1.3978)\tPrec @1 0.6250 (0.6261)\t\nEpoch: [8][840/1184]\tTime 0.921 (0.823)\tLoss 1.4386 (1.3978)\tPrec @1 0.6250 (0.6262)\t\nEpoch: [8][850/1184]\tTime 0.912 (0.823)\tLoss 1.6095 (1.3981)\tPrec @1 0.5781 (0.6263)\t\nEpoch: [8][860/1184]\tTime 0.913 (0.823)\tLoss 1.3736 (1.3978)\tPrec @1 0.6406 (0.6265)\t\nEpoch: [8][870/1184]\tTime 0.910 (0.823)\tLoss 1.1984 (1.3983)\tPrec @1 0.6875 (0.6261)\t\nEpoch: [8][880/1184]\tTime 0.921 (0.823)\tLoss 1.1112 (1.3981)\tPrec @1 0.6875 (0.6262)\t\nEpoch: [8][890/1184]\tTime 0.911 (0.823)\tLoss 1.3684 (1.3975)\tPrec @1 0.5781 (0.6262)\t\nEpoch: [8][900/1184]\tTime 0.921 (0.823)\tLoss 1.4731 (1.3970)\tPrec @1 0.6094 (0.6264)\t\nEpoch: [8][910/1184]\tTime 0.922 (0.823)\tLoss 1.0405 (1.3957)\tPrec @1 0.6875 (0.6267)\t\nEpoch: [8][920/1184]\tTime 0.915 (0.823)\tLoss 1.7765 (1.3966)\tPrec @1 0.6094 (0.6265)\t\nEpoch: [8][930/1184]\tTime 0.911 (0.823)\tLoss 1.4774 (1.3964)\tPrec @1 0.6094 (0.6266)\t\nEpoch: [8][940/1184]\tTime 0.920 (0.823)\tLoss 1.5412 (1.3962)\tPrec @1 0.6094 (0.6265)\t\nEpoch: [8][950/1184]\tTime 0.914 (0.823)\tLoss 1.4045 (1.3957)\tPrec @1 0.7188 (0.6268)\t\nEpoch: [8][960/1184]\tTime 0.912 (0.823)\tLoss 1.1479 (1.3954)\tPrec @1 0.7188 (0.6271)\t\nEpoch: [8][970/1184]\tTime 0.920 (0.823)\tLoss 1.7132 (1.3967)\tPrec @1 0.6250 (0.6269)\t\nEpoch: [8][980/1184]\tTime 0.923 (0.823)\tLoss 1.7740 (1.3975)\tPrec @1 0.6250 (0.6269)\t\nEpoch: [8][990/1184]\tTime 0.910 (0.823)\tLoss 1.1075 (1.3979)\tPrec @1 0.6094 (0.6268)\t\nEpoch: [8][1000/1184]\tTime 0.912 (0.823)\tLoss 1.4579 (1.3975)\tPrec @1 0.5938 (0.6270)\t\nEpoch: [8][1010/1184]\tTime 0.921 (0.823)\tLoss 1.4378 (1.3970)\tPrec @1 0.5625 (0.6272)\t\nEpoch: [8][1020/1184]\tTime 0.914 (0.823)\tLoss 1.1243 (1.3964)\tPrec @1 0.7031 (0.6275)\t\nEpoch: [8][1030/1184]\tTime 0.923 (0.823)\tLoss 1.2745 (1.3958)\tPrec @1 0.6719 (0.6274)\t\nEpoch: [8][1040/1184]\tTime 0.924 (0.823)\tLoss 1.1498 (1.3964)\tPrec @1 0.5938 (0.6271)\t\nEpoch: [8][1050/1184]\tTime 0.921 (0.823)\tLoss 1.6545 (1.3961)\tPrec @1 0.5469 (0.6272)\t\nEpoch: [8][1060/1184]\tTime 0.921 (0.823)\tLoss 1.4441 (1.3962)\tPrec @1 0.5469 (0.6274)\t\nEpoch: [8][1070/1184]\tTime 0.923 (0.823)\tLoss 1.2439 (1.3971)\tPrec @1 0.6250 (0.6272)\t\nEpoch: [8][1080/1184]\tTime 0.913 (0.823)\tLoss 1.3063 (1.3966)\tPrec @1 0.6250 (0.6271)\t\nEpoch: [8][1090/1184]\tTime 0.923 (0.823)\tLoss 1.3264 (1.3966)\tPrec @1 0.5938 (0.6270)\t\nEpoch: [8][1100/1184]\tTime 0.911 (0.823)\tLoss 1.3361 (1.3970)\tPrec @1 0.7031 (0.6269)\t\nEpoch: [8][1110/1184]\tTime 0.924 (0.823)\tLoss 1.7777 (1.3977)\tPrec @1 0.5312 (0.6268)\t\nEpoch: [8][1120/1184]\tTime 0.913 (0.823)\tLoss 1.6313 (1.3978)\tPrec @1 0.6094 (0.6268)\t\nEpoch: [8][1130/1184]\tTime 0.924 (0.823)\tLoss 1.5138 (1.3969)\tPrec @1 0.6094 (0.6269)\t\nEpoch: [8][1140/1184]\tTime 0.921 (0.823)\tLoss 1.4782 (1.3972)\tPrec @1 0.6250 (0.6269)\t\nEpoch: [8][1150/1184]\tTime 0.922 (0.824)\tLoss 1.8960 (1.3977)\tPrec @1 0.5469 (0.6269)\t\nEpoch: [8][1160/1184]\tTime 0.925 (0.824)\tLoss 1.3476 (1.3972)\tPrec @1 0.6562 (0.6270)\t\nEpoch: [8][1170/1184]\tTime 0.914 (0.824)\tLoss 1.0692 (1.3974)\tPrec @1 0.6719 (0.6268)\t\nEpoch: [8][1180/1184]\tTime 0.922 (0.824)\tLoss 1.3973 (1.3978)\tPrec @1 0.6094 (0.6268)\t\nEpoch: [8][0/395]\tTime 0.283 (0.283)\t\nEpoch: [8][10/395]\tTime 0.297 (0.291)\t\nEpoch: [8][20/395]\tTime 0.284 (0.290)\t\nEpoch: [8][30/395]\tTime 0.286 (0.290)\t\nEpoch: [8][40/395]\tTime 0.280 (0.290)\t\nEpoch: [8][50/395]\tTime 0.282 (0.289)\t\nEpoch: [8][60/395]\tTime 0.295 (0.289)\t\nEpoch: [8][70/395]\tTime 0.280 (0.288)\t\nEpoch: [8][80/395]\tTime 0.296 (0.288)\t\nEpoch: [8][90/395]\tTime 0.284 (0.288)\t\nEpoch: [8][100/395]\tTime 0.292 (0.288)\t\nEpoch: [8][110/395]\tTime 0.280 (0.288)\t\nEpoch: [8][120/395]\tTime 0.289 (0.288)\t\nEpoch: [8][130/395]\tTime 0.285 (0.288)\t\nEpoch: [8][140/395]\tTime 0.298 (0.288)\t\nEpoch: [8][150/395]\tTime 0.287 (0.288)\t\nEpoch: [8][160/395]\tTime 0.291 (0.288)\t\nEpoch: [8][170/395]\tTime 0.291 (0.288)\t\nEpoch: [8][180/395]\tTime 0.295 (0.289)\t\nEpoch: [8][190/395]\tTime 0.287 (0.289)\t\nEpoch: [8][200/395]\tTime 0.296 (0.289)\t\nEpoch: [8][210/395]\tTime 0.286 (0.289)\t\nEpoch: [8][220/395]\tTime 0.295 (0.289)\t\nEpoch: [8][230/395]\tTime 0.290 (0.289)\t\nEpoch: [8][240/395]\tTime 0.298 (0.289)\t\nEpoch: [8][250/395]\tTime 0.289 (0.289)\t\nEpoch: [8][260/395]\tTime 0.282 (0.289)\t\nEpoch: [8][270/395]\tTime 0.288 (0.288)\t\nEpoch: [8][280/395]\tTime 0.288 (0.288)\t\nEpoch: [8][290/395]\tTime 0.299 (0.288)\t\nEpoch: [8][300/395]\tTime 0.285 (0.288)\t\nEpoch: [8][310/395]\tTime 0.290 (0.288)\t\nEpoch: [8][320/395]\tTime 0.282 (0.288)\t\nEpoch: [8][330/395]\tTime 0.286 (0.288)\t\nEpoch: [8][340/395]\tTime 0.287 (0.288)\t\nEpoch: [8][350/395]\tTime 0.297 (0.288)\t\nEpoch: [8][360/395]\tTime 0.292 (0.288)\t\nEpoch: [8][370/395]\tTime 0.297 (0.288)\t\nEpoch: [8][380/395]\tTime 0.285 (0.288)\t\nEpoch: [8][390/395]\tTime 0.286 (0.288)\t\nAccuracy of Class 0: 0.2400\nAccuracy of Class 1: 0.6280\nAccuracy of Class 2: 0.6880\nAccuracy of Class 3: 0.7600\nAccuracy of Class 4: 0.6520\nAccuracy of Class 5: 0.5200\nAccuracy of Class 6: 0.8320\nAccuracy of Class 7: 0.8000\nAccuracy of Class 8: 0.3840\nAccuracy of Class 9: 0.3280\nAccuracy of Class 10: 0.5640\nAccuracy of Class 11: 0.7680\nAccuracy of Class 12: 0.6200\nAccuracy of Class 13: 0.6800\nAccuracy of Class 14: 0.6760\nAccuracy of Class 15: 0.3960\nAccuracy of Class 16: 0.6800\nAccuracy of Class 17: 0.4840\nAccuracy of Class 18: 0.3720\nAccuracy of Class 19: 0.6440\nAccuracy of Class 20: 0.7320\nAccuracy of Class 21: 0.6400\nAccuracy of Class 22: 0.3440\nAccuracy of Class 23: 0.7680\nAccuracy of Class 24: 0.7680\nAccuracy of Class 25: 0.7440\nAccuracy of Class 26: 0.5320\nAccuracy of Class 27: 0.7320\nAccuracy of Class 28: 0.7640\nAccuracy of Class 29: 0.7760\nAccuracy of Class 30: 0.8520\nAccuracy of Class 31: 0.6520\nAccuracy of Class 32: 0.8600\nAccuracy of Class 33: 0.9880\nAccuracy of Class 34: 0.7520\nAccuracy of Class 35: 0.7720\nAccuracy of Class 36: 0.5720\nAccuracy of Class 37: 0.4520\nAccuracy of Class 38: 0.7640\nAccuracy of Class 39: 0.3680\nAccuracy of Class 40: 0.8080\nAccuracy of Class 41: 0.6880\nAccuracy of Class 42: 0.5840\nAccuracy of Class 43: 0.7360\nAccuracy of Class 44: 0.7560\nAccuracy of Class 45: 0.7400\nAccuracy of Class 46: 0.5600\nAccuracy of Class 47: 0.4200\nAccuracy of Class 48: 0.6640\nAccuracy of Class 49: 0.4880\nAccuracy of Class 50: 0.3680\nAccuracy of Class 51: 0.8720\nAccuracy of Class 52: 0.6800\nAccuracy of Class 53: 0.6000\nAccuracy of Class 54: 0.8960\nAccuracy of Class 55: 0.6320\nAccuracy of Class 56: 0.3120\nAccuracy of Class 57: 0.3880\nAccuracy of Class 58: 0.5240\nAccuracy of Class 59: 0.4560\nAccuracy of Class 60: 0.8000\nAccuracy of Class 61: 0.6600\nAccuracy of Class 62: 0.5880\nAccuracy of Class 63: 0.9000\nAccuracy of Class 64: 0.8120\nAccuracy of Class 65: 0.8240\nAccuracy of Class 66: 0.4080\nAccuracy of Class 67: 0.2560\nAccuracy of Class 68: 0.8640\nAccuracy of Class 69: 0.8600\nAccuracy of Class 70: 0.8160\nAccuracy of Class 71: 0.6640\nAccuracy of Class 72: 0.7200\nAccuracy of Class 73: 0.5720\nAccuracy of Class 74: 0.5960\nAccuracy of Class 75: 0.8240\nAccuracy of Class 76: 0.7800\nAccuracy of Class 77: 0.3840\nAccuracy of Class 78: 0.7360\nAccuracy of Class 79: 0.7600\nAccuracy of Class 80: 0.5840\nAccuracy of Class 81: 0.6120\nAccuracy of Class 82: 0.3080\nAccuracy of Class 83: 0.8400\nAccuracy of Class 84: 0.5240\nAccuracy of Class 85: 0.5680\nAccuracy of Class 86: 0.7920\nAccuracy of Class 87: 0.5240\nAccuracy of Class 88: 0.8680\nAccuracy of Class 89: 0.5960\nAccuracy of Class 90: 0.8000\nAccuracy of Class 91: 0.8400\nAccuracy of Class 92: 0.6160\nAccuracy of Class 93: 0.2800\nAccuracy of Class 94: 0.7000\nAccuracy of Class 95: 0.6000\nAccuracy of Class 96: 0.3960\nAccuracy of Class 97: 0.6560\nAccuracy of Class 98: 0.6200\nAccuracy of Class 99: 0.4240\nAccuracy of Class 100: 0.7480\n* Prec @1: 0.6380\nEpoch: [9][0/1184]\tTime 0.020 (0.020)\tLoss 1.1665 (1.1665)\tPrec @1 0.6250 (0.6250)\t\nEpoch: [9][10/1184]\tTime 0.908 (0.746)\tLoss 1.1685 (1.2492)\tPrec @1 0.7188 (0.6676)\t\nEpoch: [9][20/1184]\tTime 0.910 (0.782)\tLoss 1.3092 (1.3178)\tPrec @1 0.6875 (0.6443)\t\nEpoch: [9][30/1184]\tTime 0.914 (0.796)\tLoss 1.2506 (1.3192)\tPrec @1 0.6562 (0.6436)\t\nEpoch: [9][40/1184]\tTime 0.923 (0.803)\tLoss 1.4425 (1.3207)\tPrec @1 0.6094 (0.6425)\t\nEpoch: [9][50/1184]\tTime 0.923 (0.808)\tLoss 1.6119 (1.3558)\tPrec @1 0.6406 (0.6348)\t\nEpoch: [9][60/1184]\tTime 0.925 (0.811)\tLoss 1.0558 (1.3500)\tPrec @1 0.6875 (0.6363)\t\nEpoch: [9][70/1184]\tTime 0.914 (0.814)\tLoss 1.4036 (1.3629)\tPrec @1 0.6094 (0.6340)\t\nEpoch: [9][80/1184]\tTime 0.925 (0.816)\tLoss 1.5756 (1.3619)\tPrec @1 0.5469 (0.6333)\t\nEpoch: [9][90/1184]\tTime 0.921 (0.817)\tLoss 1.3613 (1.3679)\tPrec @1 0.6562 (0.6331)\t\nEpoch: [9][100/1184]\tTime 0.923 (0.818)\tLoss 1.6621 (1.3819)\tPrec @1 0.5469 (0.6298)\t\nEpoch: [9][110/1184]\tTime 0.923 (0.819)\tLoss 1.5338 (1.3819)\tPrec @1 0.6094 (0.6295)\t\nEpoch: [9][120/1184]\tTime 0.922 (0.820)\tLoss 1.1525 (1.3844)\tPrec @1 0.7188 (0.6306)\t\nEpoch: [9][130/1184]\tTime 0.923 (0.820)\tLoss 1.1953 (1.3851)\tPrec @1 0.6250 (0.6300)\t\nEpoch: [9][140/1184]\tTime 0.923 (0.821)\tLoss 1.0229 (1.3883)\tPrec @1 0.6562 (0.6295)\t\nEpoch: [9][150/1184]\tTime 0.911 (0.821)\tLoss 1.3207 (1.3911)\tPrec @1 0.6094 (0.6281)\t\nEpoch: [9][160/1184]\tTime 0.924 (0.822)\tLoss 1.8704 (1.3886)\tPrec @1 0.6250 (0.6293)\t\nEpoch: [9][170/1184]\tTime 0.917 (0.822)\tLoss 1.4975 (1.3914)\tPrec @1 0.5938 (0.6289)\t\nEpoch: [9][180/1184]\tTime 0.926 (0.822)\tLoss 1.2343 (1.3880)\tPrec @1 0.6562 (0.6309)\t\nEpoch: [9][190/1184]\tTime 0.917 (0.823)\tLoss 1.5068 (1.3873)\tPrec @1 0.6250 (0.6306)\t\nEpoch: [9][200/1184]\tTime 0.923 (0.823)\tLoss 1.1634 (1.3944)\tPrec @1 0.6875 (0.6290)\t\nEpoch: [9][210/1184]\tTime 0.924 (0.823)\tLoss 1.4787 (1.3947)\tPrec @1 0.6719 (0.6289)\t\nEpoch: [9][220/1184]\tTime 0.922 (0.823)\tLoss 1.2879 (1.3972)\tPrec @1 0.6562 (0.6278)\t\nEpoch: [9][230/1184]\tTime 0.920 (0.824)\tLoss 1.2508 (1.3964)\tPrec @1 0.6250 (0.6283)\t\nEpoch: [9][240/1184]\tTime 0.926 (0.824)\tLoss 1.3471 (1.3994)\tPrec @1 0.6406 (0.6274)\t\nEpoch: [9][250/1184]\tTime 0.926 (0.824)\tLoss 1.4752 (1.4050)\tPrec @1 0.5781 (0.6266)\t\nEpoch: [9][260/1184]\tTime 0.921 (0.824)\tLoss 1.3937 (1.4082)\tPrec @1 0.6719 (0.6257)\t\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import matplotlib.pyplot as plt\ndef my_plot(epochs, loss):\n    plt.plot(epochs, loss)\nmy_plot(np.linspace(1, 10, 10).astype(int), train_acc)\nmy_plot(np.linspace(1, 10, 10).astype(int), val_acc)\nplt.legend(['train', 'val'], loc='upper left')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.savefig('/dbfs/mnt/images/accuracy_0.02_true.png')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96e33b3f-c610-4a83-84ca-7bbec144c381"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["my_plot(np.linspace(1, 10, 10).astype(int), train_loss)\nmy_plot(np.linspace(1, 10, 10).astype(int), val_loss)\nplt.legend(['train', 'val'], loc='upper left')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.savefig('/dbfs/mnt/images/loss_0.02_true.png')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0be862f7-451e-4fde-8b62-6193e2193625"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21db71d8-f70b-4868-abc3-8bb8ad156400"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Image Classification","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2617441281338072}},"nbformat":4,"nbformat_minor":0}
